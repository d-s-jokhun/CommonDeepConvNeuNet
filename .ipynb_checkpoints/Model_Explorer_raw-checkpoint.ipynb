{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataPartition import DataPartition\n",
    "from im_import import Import_GrayImg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import ModifiedModels\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from RegularizeModel import RegularizeModel\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the input X and Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes available :\n",
      " ['0_DMSO_Complete', 'DMSO', 'caffeine', 'chlorphenamine', 'estradiol', 'paracetamol']\n"
     ]
    }
   ],
   "source": [
    "MasterPath = os.path.abspath(\"/gpfs0/home/jokhun/\")\n",
    "# MasterPath = os.path.abspath('//fs9.nus.edu.sg/bie/MBELab/jokhun/Pro 1/U2OS small mol screening')\n",
    "\n",
    "Segmented_MasterFolder = 'Segmented_SmallMol'\n",
    "\n",
    "Classes = sorted([Class for Class in os.listdir(os.path.join(MasterPath,Segmented_MasterFolder)) \n",
    "           if os.path.isdir(os.path.join(MasterPath,Segmented_MasterFolder,Class))])\n",
    "print('Classes available :\\n',Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the following cell to select specific classes rather than all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes selected :\n",
      " ['DMSO', 'caffeine', 'chlorphenamine', 'paracetamol']\n",
      "No. of Images available =  20014\n",
      "DMSO  :  6000\n",
      "caffeine  :  3104\n",
      "chlorphenamine  :  7467\n",
      "paracetamol  :  3443\n"
     ]
    }
   ],
   "source": [
    "Select_Classes = True # Set to False in order to select all available classes\n",
    "selection = [1,2,3,5] # List of classes to be selected. Only used if Select_Classes is True\n",
    "\n",
    "if Select_Classes:\n",
    "    Selected_Classes = list(operator.itemgetter(*selection)(Classes))\n",
    "else:\n",
    "    Selected_Classes = Classes\n",
    "\n",
    "ClassPaths={}\n",
    "for Class in Selected_Classes:\n",
    "    ClassPaths[Class]=sorted(glob.glob(os.path.join(\n",
    "        MasterPath,Segmented_MasterFolder,Class,f\"*_{Class}.tif\"\n",
    "    )))\n",
    "\n",
    "print('Classes selected :\\n',Selected_Classes)\n",
    "print('No. of Images available = ', np.sum([len(ClassPaths[Class]) for Class in ClassPaths]))\n",
    "for Class in ClassPaths: print (Class,' : ',len(ClassPaths[Class]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Paths selected =  12416\n",
      "DMSO  :  3104\n",
      "caffeine  :  3104\n",
      "chlorphenamine  :  3104\n",
      "paracetamol  :  3104\n"
     ]
    }
   ],
   "source": [
    "# Using the smallest dataset to determine the number of images to import from each class\n",
    "MinDatasetSizes=np.amin([len(items[1]) for items in ClassPaths.items()])\n",
    "np.random.seed(0)\n",
    "\n",
    "for Class in ClassPaths.keys():\n",
    "    ClassPaths[Class]=sorted(np.random.choice(ClassPaths[Class], \n",
    "                                              size = MinDatasetSizes, replace = False))\n",
    "XPaths = []\n",
    "for Class in ClassPaths.keys():\n",
    "    XPaths.extend(ClassPaths[Class])\n",
    "\n",
    "print('No. of Paths selected = ', len(XPaths))\n",
    "for Class in ClassPaths: print (Class,' : ',len(ClassPaths[Class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partitioning data X and creating labels Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paths = 11796\n",
      "Length of Training Set = 9933\n",
      "Classes in Training Set : ['DMSO' 'caffeine' 'chlorphenamine' 'paracetamol'] --- Frequencies : [2484 2468 2514 2467]\n",
      "Length of Validation Set = 1242\n",
      "Classes in Validation Set : ['DMSO' 'caffeine' 'chlorphenamine' 'paracetamol'] --- Frequencies : [321 321 270 330]\n",
      "Length of Test Set = 621\n",
      "Classes in Test Set : ['DMSO' 'caffeine' 'chlorphenamine' 'paracetamol'] --- Frequencies : [144 150 163 164]\n",
      "\n",
      "1st element of Training Set : paracetamol\n",
      "/gpfs0/home/jokhun/Segmented_SmallMol/paracetamol/24310_a12_s4_30_paracetamol.tif\n",
      "1st element of Validation Set : DMSO\n",
      "/gpfs0/home/jokhun/Segmented_SmallMol/DMSO/25938_m14_s3_1_DMSO.tif\n",
      "1st element of Test Set : paracetamol\n",
      "/gpfs0/home/jokhun/Segmented_SmallMol/paracetamol/25986_a12_s6_46_paracetamol.tif\n"
     ]
    }
   ],
   "source": [
    "# Y can be determined either from the filenames or the folders from which the images are loaded\n",
    "\n",
    "get_labels_from = 'folders' # 'Filenames' or 'Folders'\n",
    "\n",
    "Tr_Paths, Val_Paths, Ts_Paths = DataPartition(sorted(XPaths), \n",
    "                                              Partition=[0.8,0.10,0.05], RanSeed=0)\n",
    "\n",
    "if get_labels_from.lower() == 'filenames':\n",
    "    Tr_Y = [path[path.rindex('_') + 1 : path.index('.tif')] for path in Tr_Paths]\n",
    "    Val_Y = [path[path.rindex('_') + 1 : path.index('.tif')] for path in Val_Paths]\n",
    "    Ts_Y = [path[path.rindex('_') + 1 : path.index('.tif')] for path in Ts_Paths]\n",
    "\n",
    "elif get_labels_from.lower() == 'folders':\n",
    "    Tr_Y = [os.path.basename(os.path.dirname(path)) for path in Tr_Paths]\n",
    "    Val_Y = [os.path.basename(os.path.dirname(path)) for path in Val_Paths]\n",
    "    Ts_Y = [os.path.basename(os.path.dirname(path)) for path in Ts_Paths]\n",
    "    \n",
    "else: sys.exit(\"Invalid entry for 'get_labels_from'!\")\n",
    "\n",
    "print ('Total number of paths = ' + str(len(Tr_Paths)+len(Val_Paths)+len(Ts_Paths)))\n",
    "print ('Length of Training Set = ' + str(len(Tr_Paths)))\n",
    "values, counts = np.unique(Tr_Y, return_counts=True)\n",
    "print ('Classes in Training Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "print ('Length of Validation Set = ' + str(len(Val_Paths)))\n",
    "values, counts = np.unique(Val_Y, return_counts=True)\n",
    "print ('Classes in Validation Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "print ('Length of Test Set = ' + str(len(Ts_Paths)))\n",
    "values, counts = np.unique(Ts_Y, return_counts=True)\n",
    "print ('Classes in Test Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "\n",
    "print (f'\\n1st element of Training Set : {Tr_Y[0]}\\n' + str(Tr_Paths[0]))\n",
    "print (f'1st element of Validation Set : {Val_Y[0]}\\n' + str(Val_Paths[0]))\n",
    "print (f'1st element of Test Set : {Ts_Y[0]}\\n' + str(Ts_Paths[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import images: Tr_X, Val_X and Ts_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed during import = 5.006888542324305 s\n",
      "Length of Training Set = 9933\n",
      "Length of Validation Set = 1242\n",
      "Length of Test Set = 621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Text(0.5, 1.0, 'Test[0]'), <matplotlib.image.AxesImage at 0x7f709a55c190>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ImgScaleFactor = 4\n",
    "DesiredImgSize = 224\n",
    "\n",
    "start=time.perf_counter()\n",
    "with mp.Pool() as pool:\n",
    "    Tr_X = pool.starmap(Import_GrayImg, [(path,ImgScaleFactor,DesiredImgSize) for path in Tr_Paths])\n",
    "    Val_X = pool.starmap(Import_GrayImg, [(path,ImgScaleFactor,DesiredImgSize) for path in Val_Paths])\n",
    "    Ts_X = pool.starmap(Import_GrayImg, [(path,ImgScaleFactor,DesiredImgSize) for path in Ts_Paths])\n",
    "print('Time elapsed during import = '+ str(time.perf_counter() - start) + ' s')\n",
    "\n",
    "print ('Length of Training Set = '+str(len(Tr_X)))\n",
    "print ('Length of Validation Set = '+str(len(Val_X)))\n",
    "print ('Length of Test Set = '+str(len(Ts_X)))\n",
    "\n",
    "plt.subplot(1,3,1).set_title('Train[0]'), plt.imshow(Tr_X[0], cmap='gray', norm=matplotlib.colors.Normalize())\n",
    "plt.subplot(1,3,2).set_title('Val[0]'), plt.imshow(Val_X[0], cmap='gray', norm=matplotlib.colors.Normalize())\n",
    "plt.subplot(1,3,3).set_title('Test[0]'), plt.imshow(Ts_X[0], cmap='gray', norm=matplotlib.colors.Normalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of invalid files = 18\n",
      "Classes in Training Set : ['DMSO' 'caffeine' 'chlorphenamine' 'paracetamol'] --- Frequencies : [2480 2462 2511 2463]\n",
      "Classes in Validation Set : ['DMSO' 'caffeine' 'chlorphenamine' 'paracetamol'] --- Frequencies : [321 320 270 330]\n",
      "Classes in Test Set : ['DMSO' 'caffeine' 'chlorphenamine' 'paracetamol'] --- Frequencies : [144 150 163 164]\n",
      "\n",
      "Invalid Traininig files = 17\n",
      "['/gpfs0/home/jokhun/Segmented_SmallMol/paracetamol/24311_a12_s3_22_paracetamol.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/caffeine/25966_c09_s1_2_caffeine.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/chlorphenamine/26247_i10_s1_0_chlorphenamine.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/caffeine/24306_c09_s6_27_caffeine.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/DMSO/25965_e17_s2_15_DMSO.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/DMSO/24312_f01_s5_1_DMSO.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/chlorphenamine/24294_b11_s5_11_chlorphenamine.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/caffeine/24352_c09_s5_3_caffeine.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/caffeine/25955_c09_s4_6_caffeine.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/paracetamol/24311_a12_s2_36_paracetamol.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/DMSO/24313_c12_s2_25_DMSO.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/chlorphenamine/25937_b11_s6_0_chlorphenamine.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/caffeine/24306_c09_s1_12_caffeine.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/paracetamol/24313_a12_s2_38_paracetamol.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/caffeine/24307_c09_s5_12_caffeine.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/DMSO/24294_a13_s1_29_DMSO.tif'\n",
      " '/gpfs0/home/jokhun/Segmented_SmallMol/paracetamol/25985_a12_s1_4_paracetamol.tif']\n",
      "\n",
      "Invalid Val files = 1\n",
      "['/gpfs0/home/jokhun/Segmented_SmallMol/caffeine/24352_c09_s6_10_caffeine.tif']\n",
      "\n",
      "Invalid Test files = 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Getting rid of invalid images (if th enucleus was too large to fit within 'DesiredImgSize')\n",
    "Invalid_Tr = [i for i,val in enumerate(Tr_X) if type(val)==type(None)]\n",
    "for idx in sorted(Invalid_Tr, reverse=True):\n",
    "    del Tr_X[idx]\n",
    "    del Tr_Y[idx]\n",
    "\n",
    "Invalid_Val = [i for i,val in enumerate(Val_X) if type(val)==type(None)]\n",
    "for idx in sorted(Invalid_Val, reverse=True):\n",
    "    del Val_X[idx]\n",
    "    del Val_Y[idx]\n",
    "\n",
    "Invalid_Ts = [i for i,val in enumerate(Ts_X) if type(val)==type(None)]\n",
    "for idx in sorted(Invalid_Ts, reverse=True):\n",
    "    del Ts_X[idx]\n",
    "    del Ts_Y[idx]\n",
    "\n",
    "print ('Total number of invalid files = '+str(len(Invalid_Tr)+len(Invalid_Val)+len(Invalid_Ts)))\n",
    "values, counts = np.unique(Tr_Y, return_counts=True)\n",
    "print ('Classes in Training Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "values, counts = np.unique(Val_Y, return_counts=True)\n",
    "print ('Classes in Validation Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "values, counts = np.unique(Ts_Y, return_counts=True)\n",
    "print ('Classes in Test Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "\n",
    "print('\\nInvalid Traininig files = '+str(len(Invalid_Tr))+'\\n'+str(operator.itemgetter(Invalid_Tr)(Tr_Paths)))\n",
    "print('\\nInvalid Val files = '+str(len(Invalid_Val))+'\\n'+str(operator.itemgetter(Invalid_Val)(Val_Paths)))\n",
    "print('\\nInvalid Test files = '+str(len(Invalid_Ts))+'\\n'+str(operator.itemgetter(Invalid_Ts)(Ts_Paths)))\n",
    "Tr_Paths = np.delete(Tr_Paths,Invalid_Tr)\n",
    "Val_Paths = np.delete(Val_Paths,Invalid_Val)\n",
    "Ts_Paths = np.delete(Ts_Paths,Invalid_Ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restructuring the image dataset and encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n",
      "X_Train shape:(9916, 224, 224, 1)   X_Val shape:(1241, 224, 224, 1)   X_Test shape:(621, 224, 224, 1)\n",
      "Number of calsses in the data: 4\n",
      "Classes in the Data: ['DMSO' 'caffeine' 'chlorphenamine' 'paracetamol']\n",
      "1st element of Tr_Y, Val_Y and Ts_Y : paracetamol, DMSO, paracetamol\n",
      "1st element of Y_Train, Y_Val and Y_Test : 3, 0, 3\n"
     ]
    }
   ],
   "source": [
    "X_Train = tf.expand_dims(Tr_X, axis=-1)\n",
    "X_Val = tf.expand_dims(Val_X, axis=-1)\n",
    "X_Test = tf.expand_dims(Ts_X, axis=-1)\n",
    "print('X_Train shape:'+str(X_Train.shape) + '   X_Val shape:' + str(X_Val.shape) + '   X_Test shape:' + str(X_Test.shape))\n",
    "\n",
    "ResponseEncoder = LabelEncoder()\n",
    "ResponseEncoder.fit((Tr_Y + Val_Y + Ts_Y))\n",
    "NumOfClasses = len(ResponseEncoder.classes_)\n",
    "print('Number of calsses in the data: '+str(NumOfClasses))\n",
    "print('Classes in the Data: ' + str(ResponseEncoder.classes_))\n",
    "Y_Train = ResponseEncoder.transform(Tr_Y)\n",
    "Y_Val = ResponseEncoder.transform(Val_Y)\n",
    "Y_Test = ResponseEncoder.transform(Ts_Y)\n",
    "print ('1st element of Tr_Y, Val_Y and Ts_Y : ' + str(Tr_Y[0]) + ', ' + str(Val_Y[0]) + ', ' + str(Ts_Y[0]))\n",
    "print ('1st element of Y_Train, Y_Val and Y_Test : ' + str(Y_Train[0]) + ', ' + str(Y_Val[0]) + ', ' + str(Y_Test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the untrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Test Loss and Accuracy\n",
      "mod_Xception_raw : [1.3862947225570679, 0.2415459007024765]\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "#     'mod_NASNetLarge' : ModifiedModels.mod_NASNetLarge(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "    'mod_Xception_raw' : ModifiedModels.mod_Xception(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "#     'mod_InceptionResNetV2' : ModifiedModels.mod_InceptionResNetV2(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "#     'mod_InceptionV3' : ModifiedModels.mod_InceptionV3(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "#     'mod_VGG19' : ModifiedModels.mod_VGG19(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "#     'mod_ResNet50V2' : ModifiedModels.mod_ResNet50V2(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "#     'mod_VGG16' : ModifiedModels.mod_VGG16(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]), \n",
    "#     'mod_ResNet50' : ModifiedModels.mod_ResNet50(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "}\n",
    "\n",
    "ModelKeys=list(models.keys())\n",
    "\n",
    "print('Initial Test Loss and Accuracy')\n",
    "InitialEval=[]\n",
    "for ModelKey in ModelKeys:\n",
    "    eval=models[ModelKey].evaluate(X_Test,Y_Test, verbose=0)\n",
    "    InitialEval.append(str(ModelKey)+' : '+str(eval))\n",
    "print ('\\n'.join(InitialEval)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Regularization to all regularizable layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegularizeTheModel = False\n",
    "if RegularizeTheModel:\n",
    "    regularizer = tf.keras.regularizers.l1_l2(l1=0, l2=0)\n",
    "    for ModelKey in ModelKeys:\n",
    "        models[ModelKey]=RegularizeModel(models[ModelKey], regularizer, keep_weights=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Displaying model description\n",
    "# model2view = 0 \n",
    "\n",
    "# mdl = models[ModelKeys[model2view]]\n",
    "# # mdl.summary()\n",
    "# # plot_model(mdl, to_file=f\"{list(models.keys())[model2view]}.png\", \n",
    "# #            show_shapes=True, show_layer_names=True, rankdir=\"TB\", expand_nested=True, dpi=96)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImgGrayscale (img):\n",
    "    bw = img>0\n",
    "    img = np.subtract(img, np.amin(img))\n",
    "    img = np.divide(img, np.amax(img))\n",
    "    img = img*bw   \n",
    "    return img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.0,\n",
    "    height_shift_range=0.0,\n",
    "    brightness_range=None,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.0,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode=\"constant\",\n",
    "    cval=0,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=None,\n",
    "    preprocessing_function=ImgGrayscale,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the models, saving modelcheckpoints and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training mod_Xception_raw...\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "154/154 [============================>.] - ETA: 0s - loss: 1.4226 - accuracy: 0.2547WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "155/154 [==============================] - 79s 513ms/step - loss: 1.4224 - accuracy: 0.2546 - val_loss: 1.3857 - val_accuracy: 0.2587\n",
      "Epoch 2/500\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      " 43/154 [=======>......................] - ETA: 53s - loss: 1.4090 - accuracy: 0.2591"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-35:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/mbi/home/jokhun/.conda/envs/ML/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/mnt/mbi/home/jokhun/.conda/envs/ML/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/mbi/home/jokhun/.conda/envs/ML/lib/python3.7/multiprocessing/pool.py\", line 127, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/mnt/mbi/home/jokhun/.conda/envs/ML/lib/python3.7/multiprocessing/queues.py\", line 358, in put\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/mnt/mbi/home/jokhun/.conda/envs/ML/lib/python3.7/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-af36be7f922e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMdlChkpt_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBoard_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_Val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=64; Epochs2TrainFor=500; DatagenShuffleSeed=0;\n",
    "\n",
    "Start=time.perf_counter()\n",
    "for ModelKey in ModelKeys:\n",
    "    ModelStart=time.perf_counter()\n",
    "    print('\\nTraining '+str(ModelKey)+'...')\n",
    "        \n",
    "    Model_Path = os.path.join(MasterPath,str(ModelKey))\n",
    "    \n",
    "    MdlChkpt_Path = os.path.join(Model_Path,\"MdlChkpt\",\"e{epoch:03d}_Acc{accuracy:.2f}_ValAcc{val_accuracy:.2f}.ckpt\")\n",
    "    MdlChkpt_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        MdlChkpt_Path, monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=True, \n",
    "        mode='auto', save_freq=\"epoch\"\n",
    "    )\n",
    "    TensorBoard_Path = os.path.join(Model_Path,\"logs\")\n",
    "    TensorBoard_cb = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir = TensorBoard_Path, histogram_freq=0, write_graph=False, write_images=False, update_freq=\"epoch\", \n",
    "        profile_batch=0, embeddings_freq=0, embeddings_metadata=None\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        initial_epoch = models[ModelKey]._maybe_load_initial_epoch_from_ckpt(final_epoch, 'mode')\n",
    "    except:\n",
    "        initial_epoch = 0 \n",
    "\n",
    "    final_epoch = initial_epoch + Epochs2TrainFor\n",
    "    \n",
    "    models[ModelKey].fit(\n",
    "        datagen.flow(x=X_Train, y=Y_Train, batch_size=batch_size,shuffle=True,sample_weight=None,seed=DatagenShuffleSeed,\n",
    "                     save_to_dir=None,save_prefix=\"\",save_format=\"png\",subset=None), \n",
    "        initial_epoch=initial_epoch, epochs=final_epoch, steps_per_epoch=len(X_Train)/batch_size, \n",
    "        verbose=1, callbacks=[MdlChkpt_cb, TensorBoard_cb], \n",
    "        validation_data=(X_Val,Y_Val), shuffle=True, use_multiprocessing=True\n",
    "    )\n",
    "       \n",
    "    print('\\n'+str(ModelKey)+' trained! Training time = '+ str((time.perf_counter()-ModelStart)/60) + ' min!')\n",
    "    print('Test Loss and Accuracy [Initial] [Final]')\n",
    "    for i,ModelKey in enumerate(ModelKeys):\n",
    "        eval=models[ModelKey].evaluate(X_Test,Y_Test, verbose=0)\n",
    "        print(InitialEval[i]+' '+str(eval))\n",
    "print('\\nTotal training time = '+ str((time.perf_counter()-Start)/(60*60)) + ' hr!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl=models[list(models.keys())[0]]\n",
    "print(mdl.layers[2].losses)\n",
    "mdl.layers[2].get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the latest version of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ModelKey in ModelKeys:\n",
    "    print('\\nSaving '+str(ModelKey))\n",
    "    Save_Path = os.path.join(MasterPath,str(ModelKey),\"LatestModel\")\n",
    "    models[ModelKey].save(\n",
    "        Save_Path, overwrite=False, include_optimizer=True, save_format=None,\n",
    "        signatures=None, options=None\n",
    "    )\n",
    "print('\\nThe latest version of each model has been saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
