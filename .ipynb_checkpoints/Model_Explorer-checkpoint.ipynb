{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataPartition import DataPartition\n",
    "from im_import import Import_GrayImg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from mdl_nCh_adjuster import mdl_nCh_adjuster\n",
    "import os\n",
    "import sys\n",
    "from RegularizeModel import RegularizeModel\n",
    "from SaveModelDescript import SaveModelDescript\n",
    "from ModelEditor import ModelEditor\n",
    "from get_CompileParams import get_CompileParams\n",
    "import Lambda_functions\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the input X and Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes available :\n",
      " ['0_DMSO_Complete', 'DMSO', 'caffeine', 'chlorphenamine', 'estradiol', 'paracetamol']\n"
     ]
    }
   ],
   "source": [
    "# MasterPath = os.path.abspath(\"/gpfs0/home/jokhun/\")\n",
    "# MasterPath = os.path.abspath('//fs9.nus.edu.sg/bie/MBELab/jokhun/Pro 1/U2OS small mol screening')\n",
    "MasterPath = os.path.abspath(r\"\\\\kuehlapis.mbi.nus.edu.sg\\home\\jokhun\")\n",
    "\n",
    "Segmented_MasterFolder = 'Segmented_SmallMol'\n",
    "\n",
    "Classes = sorted([Class for Class in os.listdir(os.path.join(MasterPath,Segmented_MasterFolder)) \n",
    "           if os.path.isdir(os.path.join(MasterPath,Segmented_MasterFolder,Class))])\n",
    "print('Classes available :\\n',Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the following cell to select specific classes rather than all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes selected :\n",
      " ['DMSO', 'estradiol']\n",
      "No. of Images available =  7982\n",
      "DMSO  :  6000\n",
      "estradiol  :  1982\n"
     ]
    }
   ],
   "source": [
    "Select_Classes = True # Set to False in order to select all available classes\n",
    "selection = [1,4] # List of classes to be selected. Only used if Select_Classes is True\n",
    "\n",
    "if Select_Classes:\n",
    "    Selected_Classes = list(operator.itemgetter(*selection)(Classes))\n",
    "else:\n",
    "    Selected_Classes = Classes\n",
    "\n",
    "ClassPaths={}\n",
    "for Class in Selected_Classes:\n",
    "    ClassPaths[Class]=sorted(glob.glob(os.path.join(\n",
    "        MasterPath,Segmented_MasterFolder,Class,f\"*_{Class}.tif\"\n",
    "    )))\n",
    "\n",
    "print('Classes selected :\\n',Selected_Classes)\n",
    "print('No. of Images available = ', np.sum([len(ClassPaths[Class]) for Class in ClassPaths]))\n",
    "for Class in ClassPaths: print (Class,' : ',len(ClassPaths[Class]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Paths selected =  2048\n",
      "DMSO  :  1024\n",
      "estradiol  :  1024\n"
     ]
    }
   ],
   "source": [
    "# Using the smallest dataset to determine the number of images to import from each class\n",
    "MinDatasetSizes=1024#np.amin([len(items[1]) for items in ClassPaths.items()])\n",
    "np.random.seed(0)\n",
    "\n",
    "for Class in ClassPaths.keys():\n",
    "    ClassPaths[Class]=sorted(np.random.choice(ClassPaths[Class], \n",
    "                                              size = MinDatasetSizes, replace = False))\n",
    "XPaths = []\n",
    "for Class in ClassPaths.keys():\n",
    "    XPaths.extend(ClassPaths[Class])\n",
    "\n",
    "print('No. of Paths selected = ', len(XPaths))\n",
    "for Class in ClassPaths: print (Class,' : ',len(ClassPaths[Class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partitioning data X and creating labels Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paths = 2048\n",
      "Length of Training Set = 1639\n",
      "Classes in Training Set : ['DMSO' 'estradiol'] --- Frequencies : [810 829]\n",
      "Length of Validation Set = 307\n",
      "Classes in Validation Set : ['DMSO' 'estradiol'] --- Frequencies : [155 152]\n",
      "Length of Test Set = 102\n",
      "Classes in Test Set : ['DMSO' 'estradiol'] --- Frequencies : [59 43]\n",
      "\n",
      "1st element of Training Set : estradiol\n",
      "\\\\kuehlapis.mbi.nus.edu.sg\\home\\jokhun\\Segmented_SmallMol\\estradiol\\24294_i02_s4_34_estradiol.tif\n",
      "1st element of Validation Set : DMSO\n",
      "\\\\kuehlapis.mbi.nus.edu.sg\\home\\jokhun\\Segmented_SmallMol\\DMSO\\25986_f02_s5_82_DMSO.tif\n",
      "1st element of Test Set : DMSO\n",
      "\\\\kuehlapis.mbi.nus.edu.sg\\home\\jokhun\\Segmented_SmallMol\\DMSO\\25943_d15_s6_41_DMSO.tif\n"
     ]
    }
   ],
   "source": [
    "# Y can be determined either from the filenames or the folders from which the images are loaded\n",
    "\n",
    "get_labels_from = 'folders' # 'Filenames' or 'Folders'\n",
    "\n",
    "Tr_Paths, Val_Paths, Ts_Paths = DataPartition(sorted(XPaths), \n",
    "                                              Partition=[0.8,0.15,0.05], RanSeed=0)\n",
    "\n",
    "if get_labels_from.lower() == 'filenames':\n",
    "    Tr_Y = [path[path.rindex('_') + 1 : path.index('.tif')] for path in Tr_Paths]\n",
    "    Val_Y = [path[path.rindex('_') + 1 : path.index('.tif')] for path in Val_Paths]\n",
    "    Ts_Y = [path[path.rindex('_') + 1 : path.index('.tif')] for path in Ts_Paths]\n",
    "\n",
    "elif get_labels_from.lower() == 'folders':\n",
    "    Tr_Y = [os.path.basename(os.path.dirname(path)) for path in Tr_Paths]\n",
    "    Val_Y = [os.path.basename(os.path.dirname(path)) for path in Val_Paths]\n",
    "    Ts_Y = [os.path.basename(os.path.dirname(path)) for path in Ts_Paths]\n",
    "    \n",
    "else: sys.exit(\"Invalid entry for 'get_labels_from'!\")\n",
    "\n",
    "print ('Total number of paths = ' + str(len(Tr_Paths)+len(Val_Paths)+len(Ts_Paths)))\n",
    "print ('Length of Training Set = ' + str(len(Tr_Paths)))\n",
    "values, counts = np.unique(Tr_Y, return_counts=True)\n",
    "print ('Classes in Training Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "print ('Length of Validation Set = ' + str(len(Val_Paths)))\n",
    "values, counts = np.unique(Val_Y, return_counts=True)\n",
    "print ('Classes in Validation Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "print ('Length of Test Set = ' + str(len(Ts_Paths)))\n",
    "values, counts = np.unique(Ts_Y, return_counts=True)\n",
    "print ('Classes in Test Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "\n",
    "print (f'\\n1st element of Training Set : {Tr_Y[0]}\\n' + str(Tr_Paths[0]))\n",
    "print (f'1st element of Validation Set : {Val_Y[0]}\\n' + str(Val_Paths[0]))\n",
    "print (f'1st element of Test Set : {Ts_Y[0]}\\n' + str(Ts_Paths[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import images: Tr_X, Val_X and Ts_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed during import = 2.1735628869999744 s\n",
      "Length of Training Set = 1626\n",
      "Length of Validation Set = 305\n",
      "Length of Test Set = 102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Text(0.5, 1.0, 'Test[0]'), <matplotlib.image.AxesImage at 0x1f68b3d2b88>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ImgScaleFactor = 1\n",
    "DesiredImgSize = 64\n",
    "\n",
    "start=time.perf_counter()\n",
    "with mp.Pool() as pool:\n",
    "    Tr_X = pool.starmap(Import_GrayImg, [(path,ImgScaleFactor,DesiredImgSize) for path in Tr_Paths])\n",
    "    Val_X = pool.starmap(Import_GrayImg, [(path,ImgScaleFactor,DesiredImgSize) for path in Val_Paths])\n",
    "    Ts_X = pool.starmap(Import_GrayImg, [(path,ImgScaleFactor,DesiredImgSize) for path in Ts_Paths])\n",
    "print('Time elapsed during import = '+ str(time.perf_counter() - start) + ' s')\n",
    "\n",
    "print ('Length of Training Set = '+str(len(Tr_X)))\n",
    "print ('Length of Validation Set = '+str(len(Val_X)))\n",
    "print ('Length of Test Set = '+str(len(Ts_X)))\n",
    "\n",
    "plt.subplot(1,3,1).set_title('Train[0]'), plt.imshow(Tr_X[0], cmap='gray', norm=matplotlib.colors.Normalize())\n",
    "plt.subplot(1,3,2).set_title('Val[0]'), plt.imshow(Val_X[0], cmap='gray', norm=matplotlib.colors.Normalize())\n",
    "plt.subplot(1,3,3).set_title('Test[0]'), plt.imshow(Ts_X[0], cmap='gray', norm=matplotlib.colors.Normalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of invalid files = 0\n",
      "Classes in Training Set : ['DMSO' 'estradiol'] --- Frequencies : [807 819]\n",
      "Classes in Validation Set : ['DMSO' 'estradiol'] --- Frequencies : [154 151]\n",
      "Classes in Test Set : ['DMSO' 'estradiol'] --- Frequencies : [59 43]\n",
      "\n",
      "Invalid Traininig files = 0\n",
      "[]\n",
      "\n",
      "Invalid Val files = 0\n",
      "[]\n",
      "\n",
      "Invalid Test files = 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Getting rid of invalid images (if th enucleus was too large to fit within 'DesiredImgSize')\n",
    "Invalid_Tr = [i for i,val in enumerate(Tr_X) if type(val)==type(None)]\n",
    "for idx in sorted(Invalid_Tr, reverse=True):\n",
    "    del Tr_X[idx]\n",
    "    del Tr_Y[idx]\n",
    "\n",
    "Invalid_Val = [i for i,val in enumerate(Val_X) if type(val)==type(None)]\n",
    "for idx in sorted(Invalid_Val, reverse=True):\n",
    "    del Val_X[idx]\n",
    "    del Val_Y[idx]\n",
    "\n",
    "Invalid_Ts = [i for i,val in enumerate(Ts_X) if type(val)==type(None)]\n",
    "for idx in sorted(Invalid_Ts, reverse=True):\n",
    "    del Ts_X[idx]\n",
    "    del Ts_Y[idx]\n",
    "\n",
    "print ('Total number of invalid files = '+str(len(Invalid_Tr)+len(Invalid_Val)+len(Invalid_Ts)))\n",
    "values, counts = np.unique(Tr_Y, return_counts=True)\n",
    "print ('Classes in Training Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "values, counts = np.unique(Val_Y, return_counts=True)\n",
    "print ('Classes in Validation Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "values, counts = np.unique(Ts_Y, return_counts=True)\n",
    "print ('Classes in Test Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "\n",
    "print('\\nInvalid Traininig files = '+str(len(Invalid_Tr))+'\\n'+str(operator.itemgetter(Invalid_Tr)(Tr_Paths)))\n",
    "print('\\nInvalid Val files = '+str(len(Invalid_Val))+'\\n'+str(operator.itemgetter(Invalid_Val)(Val_Paths)))\n",
    "print('\\nInvalid Test files = '+str(len(Invalid_Ts))+'\\n'+str(operator.itemgetter(Invalid_Ts)(Ts_Paths)))\n",
    "Tr_Paths = np.delete(Tr_Paths,Invalid_Tr)\n",
    "Val_Paths = np.delete(Val_Paths,Invalid_Val)\n",
    "Ts_Paths = np.delete(Ts_Paths,Invalid_Ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restructuring the image dataset and encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train shape:(1626, 64, 64, 1)   X_Val shape:(305, 64, 64, 1)   X_Test shape:(102, 64, 64, 1)\n",
      "Number of calsses in the data: 2\n",
      "Classes in the Data: ['DMSO' 'estradiol']\n",
      "1st element of Tr_Y, Val_Y and Ts_Y : estradiol, DMSO, DMSO\n",
      "1st element of Y_Train, Y_Val and Y_Test : 1, 0, 0\n"
     ]
    }
   ],
   "source": [
    "X_Train = tf.expand_dims(Tr_X, axis=-1)\n",
    "X_Val = tf.expand_dims(Val_X, axis=-1)\n",
    "X_Test = tf.expand_dims(Ts_X, axis=-1)\n",
    "print('X_Train shape:'+str(X_Train.shape) + '   X_Val shape:' + str(X_Val.shape) + '   X_Test shape:' + str(X_Test.shape))\n",
    "\n",
    "ResponseEncoder = LabelEncoder()\n",
    "ResponseEncoder.fit(list(Tr_Y) + list(Val_Y) + list(Ts_Y))\n",
    "NumOfClasses = len(ResponseEncoder.classes_)\n",
    "print('Number of calsses in the data: '+str(NumOfClasses))\n",
    "print('Classes in the Data: ' + str(ResponseEncoder.classes_))\n",
    "Y_Train = ResponseEncoder.transform(Tr_Y)\n",
    "Y_Val = ResponseEncoder.transform(Val_Y)\n",
    "Y_Test = ResponseEncoder.transform(Ts_Y)\n",
    "print ('1st element of Tr_Y, Val_Y and Ts_Y : ' + str(Tr_Y[0]) + ', ' + str(Val_Y[0]) + ', ' + str(Ts_Y[0]))\n",
    "print ('1st element of Y_Train, Y_Val and Y_Test : ' + str(Y_Train[0]) + ', ' + str(Y_Val[0]) + ', ' + str(Y_Test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the models ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating keras models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  model/s created!\n"
     ]
    }
   ],
   "source": [
    "CreateModel = True\n",
    "\n",
    "models = {}\n",
    "if CreateModel:\n",
    "    models['try_Xception'] = tf.keras.applications.Xception(include_top=False, weights=\"imagenet\", input_shape=(299, 299, 3), pooling='avg')\n",
    "#     models['try_InceptionResNetV2'] = tf.keras.applications.InceptionResNetV2(include_top=False, weights=\"imagenet\", input_shape=(*X_Train.shape[1:3],3), pooling='avg')\n",
    "#     models['try_NASNetLarge'] = tf.keras.applications.NASNetLarge(include_top=False, weights=\"imagenet\", input_shape=(*X_Train.shape[1:3],3), pooling='avg')\n",
    "          \n",
    "    ModelKeys=list(models.keys())\n",
    "    ModelsCreated = len(ModelKeys)\n",
    "    print (str(ModelsCreated),' model/s created!')\n",
    "else:\n",
    "    print ('No model created. Load one from disk below!')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveModelDescription = False\n",
    "\n",
    "if SaveModelDescription:\n",
    "    for ModelKey in ModelKeys:\n",
    "        model = models[ModelKey]\n",
    "        Model_Path = os.path.join(MasterPath,str(ModelKey))        \n",
    "        SaveModelDescript(model, save_dir=Model_Path, \n",
    "                          save_filename=str(ModelKey))        \n",
    "    print ('Model descriptions saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Edit_Model = False\n",
    "SaveEditedModelDescription = True\n",
    "ModelKey = ModelKeys[0]\n",
    "\n",
    "if Edit_Model:\n",
    "    model = models[ModelKey]\n",
    "    New_Layers={'drop1':tf.keras.layers.Dropout(rate=0.1, name='drop1'),\n",
    "                'drop2':tf.keras.layers.Dropout(rate=0.2, name='drop2'),\n",
    "                'drop3':tf.keras.layers.Dropout(rate=0.3, name='drop3'),\n",
    "                'drop4':tf.keras.layers.Dropout(rate=0.4, name='drop4'),\n",
    "                'drop5':tf.keras.layers.Dropout(rate=0.5, name='drop5'),\n",
    "               }\n",
    "\n",
    "    IncomingLinks_2Axe=[-18, -12, -14, -8, -5, -1]   \n",
    "\n",
    "    IncomingLinks_2Forge=[(New_Layers['drop1'], model.layers[-19]),\n",
    "                          (model.layers[-18], New_Layers['drop1']),\n",
    "                          (model.layers[-12], New_Layers['drop1']),\n",
    "                          (New_Layers['drop2'], model.layers[-15]),\n",
    "                          (model.layers[-14], New_Layers['drop2']),\n",
    "                          (New_Layers['drop3'], model.layers[-9]),\n",
    "                          (model.layers[-8], New_Layers['drop3']),\n",
    "                          (New_Layers['drop4'], model.layers[-6]),\n",
    "                          (model.layers[-5], New_Layers['drop4']),\n",
    "                          (New_Layers['drop5'], model.layers[-2]),\n",
    "                          (model.layers[-1], New_Layers['drop5']),\n",
    "                         ]\n",
    "\n",
    "    model_inputs=None\n",
    "    model_outputs=None\n",
    "\n",
    "    model = ModelEditor(model, New_Layers=New_Layers, IncomingLinks_2Axe=IncomingLinks_2Axe, \n",
    "                                IncomingLinks_2Forge=IncomingLinks_2Forge,\n",
    "                                model_inputs=model_inputs, model_outputs=model_outputs)\n",
    "    models[ModelKey] = model \n",
    "    \n",
    "    # Save edited model description\n",
    "    if SaveEditedModelDescription:\n",
    "        Model_Path = os.path.join(MasterPath,str(ModelKey))        \n",
    "        SaveModelDescript(model, save_dir=Model_Path, \n",
    "                          save_filename=str(ModelKey+'_edited'))        \n",
    "        print ('Model descriptions saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Top and Bottom layers to keras models instantiated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom and Top layers added!\n"
     ]
    }
   ],
   "source": [
    "AddTopAndBottomLayers = True\n",
    "\n",
    "if AddTopAndBottomLayers:\n",
    "    ModelKeys=list(models.keys())\n",
    "    for ModelKey in ModelKeys:\n",
    "        mdl = models[ModelKey]\n",
    "        im_preprocess = mdl_nCh_adjuster(NumOfInputCh=X_Train.shape[-1], NumOfOutputCh=mdl.input_shape[-1], \n",
    "                                         InputImgSize=X_Train.shape[1:3], OutputImgSize=mdl.input_shape[1:3])\n",
    "        predictions = tf.keras.layers.Dense(units=NumOfClasses, activation=None, name=\"predictions\")\n",
    "        \n",
    "        In = tf.keras.Input(shape=(X_Train.shape[1:4]), name=\"Input\")\n",
    "        Out = predictions(mdl(im_preprocess(In)))\n",
    "        models[ModelKey] = tf.keras.Model(inputs=In, outputs=Out, name=ModelKey)\n",
    "    print ('Bottom and Top layers added!')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model descriptions saved!\n"
     ]
    }
   ],
   "source": [
    "SaveModelDescription = True\n",
    "\n",
    "if SaveModelDescription:\n",
    "    ModelKeys=list(models.keys())\n",
    "    for ModelKey in ModelKeys:\n",
    "        model = models[ModelKey]\n",
    "        Model_Path = os.path.join(MasterPath,str(ModelKey))        \n",
    "        SaveModelDescript(model, save_dir=Model_Path, \n",
    "                          save_filename=str(ModelKey))        \n",
    "    print ('Model descriptions saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models compiled!\n"
     ]
    }
   ],
   "source": [
    "CompileModels = True\n",
    "if CompileModels:\n",
    "    ModelKeys=list(models.keys())\n",
    "    for ModelKey in ModelKeys:\n",
    "        models[ModelKey].compile(optimizer='adam', \n",
    "                                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                                 metrics=['accuracy'])\n",
    "    print ('Models compiled!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading models from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model loaded from disk!\n"
     ]
    }
   ],
   "source": [
    "LoadModelFromDisk = False\n",
    "\n",
    "if LoadModelFromDisk:\n",
    "    models['mdl_name'] = tf.keras.models.load_model('mdl_path')\n",
    "    \n",
    "    ModelsLoaded = len(models.keys()) - ModelsCreated\n",
    "    print (str(ModelsLoaded),' models loaded from disk!')\n",
    "else:\n",
    "    print ('No model loaded from disk!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Regularization to all regularizable layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegularizeTheModel = False\n",
    "if RegularizeTheModel:\n",
    "    regularizer = tf.keras.regularizers.l1_l2(l1=0, l2=0.001)\n",
    "    for ModelKey in ModelKeys:\n",
    "        models[ModelKey]=RegularizeModel(models[ModelKey], regularizer, keep_weights=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models =  1\n",
      "Initial Train Loss and Accuracy\n",
      "try_Xception : [0.7021916189756781, 0.47293973]\n",
      "\n",
      "Initial Val Loss and Accuracy\n",
      "try_Xception : [0.7033749326330716, 0.46885246]\n",
      "\n",
      "Initial Test Loss and Accuracy\n",
      "try_Xception : [0.6905236618191588, 0.5588235]\n"
     ]
    }
   ],
   "source": [
    "ModelKeys=list(models.keys())\n",
    "\n",
    "print ('Total number of models = ',str(len(models.keys())))\n",
    "print ('Initial Train Loss and Accuracy')\n",
    "TrainEval=[]\n",
    "for ModelKey in ModelKeys:\n",
    "    Eval=models[ModelKey].evaluate(X_Train,Y_Train, verbose=0)\n",
    "    TrainEval.append(str(ModelKey)+' : '+str(Eval))\n",
    "print ('\\n'.join(TrainEval)) \n",
    "\n",
    "print ('\\nInitial Val Loss and Accuracy')\n",
    "ValEval=[]\n",
    "for ModelKey in ModelKeys:\n",
    "    Eval=models[ModelKey].evaluate(X_Val,Y_Val, verbose=0)\n",
    "    ValEval.append(str(ModelKey)+' : '+str(Eval))\n",
    "print ('\\n'.join(ValEval)) \n",
    "\n",
    "print ('\\nInitial Test Loss and Accuracy')\n",
    "TestEval=[]\n",
    "for ModelKey in ModelKeys:\n",
    "    Eval=models[ModelKey].evaluate(X_Test,Y_Test, verbose=0)\n",
    "    TestEval.append(str(ModelKey)+' : '+str(Eval))\n",
    "print ('\\n'.join(TestEval)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "UseImageDataGenerator = True\n",
    "\n",
    "def ImgGrayscale (img):\n",
    "    bw = img>0\n",
    "    img = np.subtract(img, np.amin(img))\n",
    "    img = np.divide(img, np.amax(img))\n",
    "    img = img*bw   \n",
    "    return img\n",
    "\n",
    "if UseImageDataGenerator:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.0,\n",
    "        height_shift_range=0.0,\n",
    "        brightness_range=None,\n",
    "        shear_range=0.0,\n",
    "        zoom_range=0.0,\n",
    "        channel_shift_range=0.0,\n",
    "        fill_mode=\"constant\",\n",
    "        cval=0,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rescale=None,\n",
    "        preprocessing_function=ImgGrayscale,\n",
    "        data_format=None,\n",
    "        validation_split=0.0,\n",
    "        dtype=None,\n",
    "    )\n",
    "else:\n",
    "    datagen = ImageDataGenerator(preprocessing_function=ImgGrayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model (model, X_Train=None, Y_Train=None, X_Val=None, Y_Val=None, batch_size=64, initial_epoch=0, final_epoch=5, Model_Path=None, shuffle=True, DatagenShuffleSeed=None):\n",
    "    if Model_Path==None or Model_Path==[]:\n",
    "        Model_Path=model.name\n",
    "\n",
    "    MdlChkpt_Path = os.path.join(Model_Path,\"MdlChkpt\",\"e{epoch:03d}_Acc{accuracy:.2f}_ValAcc{val_accuracy:.2f}.ckpt\")\n",
    "    MdlChkpt_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        MdlChkpt_Path, monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=True, \n",
    "        mode='auto', save_freq=\"epoch\"\n",
    "    )\n",
    "    TensorBoard_Path = os.path.join(Model_Path,\"logs\")\n",
    "    TensorBoard_cb = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir = TensorBoard_Path, histogram_freq=0, write_graph=False, write_images=False, update_freq=\"epoch\", \n",
    "        profile_batch=0, embeddings_freq=0, embeddings_metadata=None\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        datagen.flow(x=X_Train, y=Y_Train, batch_size=batch_size, \n",
    "                     shuffle=shuffle, sample_weight=None,seed=DatagenShuffleSeed,\n",
    "                     save_to_dir=None,save_prefix=\"\",save_format=\"png\",subset=None),\n",
    "        initial_epoch=initial_epoch, epochs=final_epoch, steps_per_epoch=len(X_Train)/batch_size, \n",
    "        verbose=1, callbacks=[MdlChkpt_cb, TensorBoard_cb], \n",
    "        validation_data=(X_Val,Y_Val), shuffle=shuffle, use_multiprocessing=False\n",
    "    )        \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training top and bottom layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the main model as non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions  core has been set as non-trainable\n"
     ]
    }
   ],
   "source": [
    "TrainTopAndBottomOnly = True\n",
    "MainModel_layer = -2\n",
    "\n",
    "if TrainTopAndBottomOnly:\n",
    "    ModelKeys=list(models.keys())\n",
    "    for ModelKey in ModelKeys:\n",
    "        model=models[ModelKey]\n",
    "        model.layers[MainModel_layer].trainable = False\n",
    "        print (model.layers[MainModel_layer].name,' has been set as non-trainable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile_args did not work. getattr was used instead.\n",
      "Models compiled!\n"
     ]
    }
   ],
   "source": [
    "if TrainTopAndBottomOnly:\n",
    "    ModelKeys = list(models.keys())\n",
    "    for ModelKey in ModelKeys:\n",
    "        model = models[ModelKey]\n",
    "        optimizer,loss,metrics,loss_weights,weighted_metrics,run_eagerly = get_CompileParams (model).values()\n",
    "        if optimizer!=None:\n",
    "            model.compile(optimizer = optimizer,\n",
    "                          loss = loss,\n",
    "                          metrics = metrics,\n",
    "                          loss_weights = loss_weights,\n",
    "                          weighted_metrics = weighted_metrics,\n",
    "                          run_eagerly = run_eagerly)\n",
    "        else:\n",
    "            model.compile(optimizer='adam', \n",
    "                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                          metrics=['accuracy'])\n",
    "    print ('Models compiled!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the top and bottom layers of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training try_Xception...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 50.8125 steps, validate on 305 samples\n",
      "Epoch 1/30\n",
      "51/50 [==============================] - 142s 3s/step - loss: 0.6955 - accuracy: 0.5031 - val_loss: 0.6931 - val_accuracy: 0.4984\n",
      "Epoch 2/30\n",
      "51/50 [==============================] - 238s 5s/step - loss: 0.6931 - accuracy: 0.4785 - val_loss: 0.6931 - val_accuracy: 0.4984\n",
      "Epoch 3/30\n",
      "51/50 [==============================] - 245s 5s/step - loss: 0.6931 - accuracy: 0.4877 - val_loss: 0.6931 - val_accuracy: 0.5213\n",
      "Epoch 4/30\n",
      "51/50 [==============================] - 241s 5s/step - loss: 0.6935 - accuracy: 0.5006 - val_loss: 0.6941 - val_accuracy: 0.4984\n",
      "Epoch 5/30\n",
      "51/50 [==============================] - 251s 5s/step - loss: 0.6927 - accuracy: 0.5172 - val_loss: 0.6950 - val_accuracy: 0.5246\n",
      "Epoch 6/30\n",
      "51/50 [==============================] - 245s 5s/step - loss: 0.6929 - accuracy: 0.4889 - val_loss: 0.6931 - val_accuracy: 0.5049\n",
      "Epoch 7/30\n",
      "51/50 [==============================] - 250s 5s/step - loss: 0.6926 - accuracy: 0.5314 - val_loss: 0.6927 - val_accuracy: 0.5148\n",
      "Epoch 8/30\n",
      "51/50 [==============================] - 250s 5s/step - loss: 0.6934 - accuracy: 0.4982 - val_loss: 0.7075 - val_accuracy: 0.4951\n",
      "Epoch 9/30\n",
      "51/50 [==============================] - 249s 5s/step - loss: 0.6922 - accuracy: 0.5209 - val_loss: 6.4627 - val_accuracy: 0.4951\n",
      "Epoch 10/30\n",
      "51/50 [==============================] - 248s 5s/step - loss: 0.6938 - accuracy: 0.4920 - val_loss: 1.5378 - val_accuracy: 0.4951\n",
      "Epoch 11/30\n",
      "51/50 [==============================] - 248s 5s/step - loss: 0.6933 - accuracy: 0.5178 - val_loss: 0.7102 - val_accuracy: 0.5148\n",
      "Epoch 12/30\n",
      "51/50 [==============================] - 251s 5s/step - loss: 0.6919 - accuracy: 0.5197 - val_loss: 0.6901 - val_accuracy: 0.5475\n",
      "Epoch 13/30\n",
      "51/50 [==============================] - 247s 5s/step - loss: 0.6922 - accuracy: 0.5166 - val_loss: 0.7478 - val_accuracy: 0.5508\n",
      "Epoch 14/30\n",
      "51/50 [==============================] - 241s 5s/step - loss: 0.6925 - accuracy: 0.5246 - val_loss: 0.6930 - val_accuracy: 0.4689\n",
      "Epoch 15/30\n",
      "51/50 [==============================] - 244s 5s/step - loss: 0.6917 - accuracy: 0.5541 - val_loss: 0.7120 - val_accuracy: 0.5180\n",
      "Epoch 16/30\n",
      "51/50 [==============================] - 249s 5s/step - loss: 0.6912 - accuracy: 0.5412 - val_loss: 0.6863 - val_accuracy: 0.5738\n",
      "Epoch 17/30\n",
      "51/50 [==============================] - 246s 5s/step - loss: 0.6908 - accuracy: 0.5308 - val_loss: 0.6927 - val_accuracy: 0.5770\n",
      "Epoch 18/30\n",
      "51/50 [==============================] - 241s 5s/step - loss: 0.6906 - accuracy: 0.5443 - val_loss: 0.6951 - val_accuracy: 0.5607\n",
      "Epoch 19/30\n",
      "51/50 [==============================] - 246s 5s/step - loss: 0.6899 - accuracy: 0.5443 - val_loss: 0.6912 - val_accuracy: 0.5836\n",
      "Epoch 20/30\n",
      "51/50 [==============================] - 241s 5s/step - loss: 0.6900 - accuracy: 0.5369 - val_loss: 0.6893 - val_accuracy: 0.5836\n",
      "Epoch 21/30\n",
      "51/50 [==============================] - 241s 5s/step - loss: 0.6899 - accuracy: 0.5566 - val_loss: 0.6899 - val_accuracy: 0.5836\n",
      "Epoch 22/30\n",
      "51/50 [==============================] - 241s 5s/step - loss: 0.6893 - accuracy: 0.5418 - val_loss: 0.7343 - val_accuracy: 0.5410\n",
      "Epoch 23/30\n",
      "51/50 [==============================] - 241s 5s/step - loss: 0.6895 - accuracy: 0.5326 - val_loss: 0.6928 - val_accuracy: 0.5770\n",
      "Epoch 24/30\n",
      "51/50 [==============================] - 242s 5s/step - loss: 0.6885 - accuracy: 0.5584 - val_loss: 0.7956 - val_accuracy: 0.5508\n",
      "Epoch 25/30\n",
      "51/50 [==============================] - 242s 5s/step - loss: 0.6884 - accuracy: 0.5560 - val_loss: 0.6911 - val_accuracy: 0.5311\n",
      "Epoch 26/30\n",
      "51/50 [==============================] - 242s 5s/step - loss: 0.6881 - accuracy: 0.5381 - val_loss: 0.6898 - val_accuracy: 0.5803\n",
      "Epoch 27/30\n",
      "51/50 [==============================] - 242s 5s/step - loss: 0.6887 - accuracy: 0.5609 - val_loss: 0.6930 - val_accuracy: 0.5574\n",
      "Epoch 28/30\n",
      "51/50 [==============================] - 246s 5s/step - loss: 0.6884 - accuracy: 0.5590 - val_loss: 0.6866 - val_accuracy: 0.5902\n",
      "Epoch 29/30\n",
      "51/50 [==============================] - 241s 5s/step - loss: 0.6892 - accuracy: 0.5510 - val_loss: 0.6995 - val_accuracy: 0.5705\n",
      "Epoch 30/30\n",
      "51/50 [==============================] - 241s 5s/step - loss: 0.6885 - accuracy: 0.5640 - val_loss: 0.6885 - val_accuracy: 0.5869\n",
      "\n",
      "try_Xception trained! Training time = 120.5804739948 min!\n",
      "\n",
      "Total training time = 2.009674604381389 hr!\n"
     ]
    }
   ],
   "source": [
    "if TrainTopAndBottomOnly:\n",
    "    Start=time.perf_counter()\n",
    "    ModelKeys=list(models.keys())\n",
    "    for ModelKey in ModelKeys:\n",
    "        ModelStart=time.perf_counter()\n",
    "        print('\\nTraining '+str(ModelKey)+'...')\n",
    "        Model_Path = os.path.join(MasterPath,str(ModelKey))\n",
    "        model = models[ModelKey]\n",
    "        \n",
    "        train_model (model, X_Train=X_Train, Y_Train=Y_Train, X_Val=X_Val, Y_Val=Y_Val, \n",
    "                     batch_size=32, initial_epoch=0, final_epoch=30,\n",
    "                     Model_Path=Model_Path, shuffle=True, DatagenShuffleSeed=None)\n",
    "        \n",
    "        print('\\n'+str(ModelKey)+' trained! Training time = '+ str((time.perf_counter()-ModelStart)/60) + ' min!')\n",
    "    print('\\nTotal training time = '+ str((time.perf_counter()-Start)/(60*60)) + ' hr!')        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models =  1\n",
      "Train Loss and Accuracy\n",
      "try_Xception : [0.688262588350242, 0.55412054]\n",
      "\n",
      "Val Loss and Accuracy\n",
      "try_Xception : [0.6884993707547422, 0.5868853]\n",
      "\n",
      "Test Loss and Accuracy\n",
      "try_Xception : [0.7091449113453135, 0.54901963]\n"
     ]
    }
   ],
   "source": [
    "print ('Total number of models = ',str(len(models.keys())))\n",
    "print ('Train Loss and Accuracy')\n",
    "TrainEval=[]\n",
    "ModelKeys=list(models.keys())\n",
    "for ModelKey in ModelKeys:\n",
    "    Eval=models[ModelKey].evaluate(X_Train,Y_Train, verbose=0)\n",
    "    TrainEval.append(str(ModelKey)+' : '+str(Eval))\n",
    "print ('\\n'.join(TrainEval)) \n",
    "\n",
    "print ('\\nVal Loss and Accuracy')\n",
    "ValEval=[]\n",
    "for ModelKey in ModelKeys:\n",
    "    Eval=models[ModelKey].evaluate(X_Val,Y_Val, verbose=0)\n",
    "    ValEval.append(str(ModelKey)+' : '+str(Eval))\n",
    "print ('\\n'.join(ValEval)) \n",
    "\n",
    "print ('\\nTest Loss and Accuracy')\n",
    "TestEval=[]\n",
    "for ModelKey in ModelKeys:\n",
    "    Eval=models[ModelKey].evaluate(X_Test,Y_Test, verbose=0)\n",
    "    TestEval.append(str(ModelKey)+' : '+str(Eval))\n",
    "print ('\\n'.join(TestEval)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training full models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the main model as trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions  core has been set as trainable\n"
     ]
    }
   ],
   "source": [
    "TrainFullModel = True\n",
    "\n",
    "if TrainFullModel:\n",
    "    ModelKeys=list(models.keys())\n",
    "    for ModelKey in ModelKeys:\n",
    "        model=models[ModelKey]\n",
    "        model.layers[MainModel_layer].trainable = True\n",
    "        print (model.layers[MainModel_layer].name,' has been set as trainable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile_args did not work. getattr was used instead.\n",
      "Models compiled!\n"
     ]
    }
   ],
   "source": [
    "if TrainFullModel:\n",
    "    ModelKeys = list(models.keys())\n",
    "    for ModelKey in ModelKeys:\n",
    "        model = models[ModelKey]\n",
    "        optimizer,loss,metrics,loss_weights,weighted_metrics,run_eagerly = get_CompileParams (model).values()\n",
    "        if optimizer!=None:\n",
    "            model.compile(optimizer = optimizer,\n",
    "                          loss = loss,\n",
    "                          metrics = metrics,\n",
    "                          loss_weights = loss_weights,\n",
    "                          weighted_metrics = weighted_metrics,\n",
    "                          run_eagerly = run_eagerly)\n",
    "        else:\n",
    "            model.compile(optimizer='adam', \n",
    "                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                          metrics=['accuracy'])\n",
    "    print ('Models compiled!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training full models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training try_Xception...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 101.625 steps, validate on 305 samples\n",
      "Epoch 31/50\n",
      "102/101 [==============================] - 280s 3s/step - loss: 0.6910 - accuracy: 0.5357 - val_loss: 1.1900 - val_accuracy: 0.4951\n",
      "Epoch 32/50\n",
      "102/101 [==============================] - 258s 3s/step - loss: 0.6904 - accuracy: 0.5394 - val_loss: 1.0772 - val_accuracy: 0.5377\n",
      "Epoch 33/50\n",
      "102/101 [==============================] - 257s 3s/step - loss: 0.6889 - accuracy: 0.5357 - val_loss: 0.6873 - val_accuracy: 0.5541\n",
      "Epoch 34/50\n",
      "102/101 [==============================] - 257s 3s/step - loss: 0.6876 - accuracy: 0.5510 - val_loss: 0.6911 - val_accuracy: 0.5639\n",
      "Epoch 35/50\n",
      "102/101 [==============================] - 253s 2s/step - loss: 0.6879 - accuracy: 0.5467 - val_loss: 0.6911 - val_accuracy: 0.5574\n",
      "Epoch 36/50\n",
      "102/101 [==============================] - 258s 3s/step - loss: 0.6846 - accuracy: 0.5523 - val_loss: 0.6899 - val_accuracy: 0.6066\n",
      "Epoch 37/50\n",
      "102/101 [==============================] - 254s 2s/step - loss: 0.6846 - accuracy: 0.5517 - val_loss: 0.6843 - val_accuracy: 0.5443\n",
      "Epoch 38/50\n",
      "102/101 [==============================] - 253s 2s/step - loss: 0.6852 - accuracy: 0.5621 - val_loss: 0.6796 - val_accuracy: 0.6066\n",
      "Epoch 39/50\n",
      "102/101 [==============================] - 258s 3s/step - loss: 0.6811 - accuracy: 0.5806 - val_loss: 0.6736 - val_accuracy: 0.6098\n",
      "Epoch 40/50\n",
      "102/101 [==============================] - 253s 2s/step - loss: 0.6814 - accuracy: 0.5627 - val_loss: 0.7833 - val_accuracy: 0.5541\n",
      "Epoch 41/50\n",
      "102/101 [==============================] - 252s 2s/step - loss: 0.6773 - accuracy: 0.5566 - val_loss: 0.7742 - val_accuracy: 0.5934\n",
      "Epoch 42/50\n",
      "102/101 [==============================] - 251s 2s/step - loss: 0.6797 - accuracy: 0.5332 - val_loss: 4.7524 - val_accuracy: 0.5279\n",
      "Epoch 43/50\n",
      "102/101 [==============================] - 252s 2s/step - loss: 0.6791 - accuracy: 0.5406 - val_loss: 0.7910 - val_accuracy: 0.5049\n",
      "Epoch 44/50\n",
      "102/101 [==============================] - 252s 2s/step - loss: 0.6961 - accuracy: 0.4834 - val_loss: 0.6991 - val_accuracy: 0.5016\n",
      "Epoch 45/50\n",
      "102/101 [==============================] - 251s 2s/step - loss: 0.6918 - accuracy: 0.5314 - val_loss: 0.6984 - val_accuracy: 0.5049\n",
      "Epoch 46/50\n",
      "102/101 [==============================] - 252s 2s/step - loss: 0.6879 - accuracy: 0.5461 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 47/50\n",
      "102/101 [==============================] - 252s 2s/step - loss: 0.6727 - accuracy: 0.5633 - val_loss: 0.6888 - val_accuracy: 0.5475\n",
      "Epoch 48/50\n",
      "102/101 [==============================] - 250s 2s/step - loss: 0.6607 - accuracy: 0.5689 - val_loss: 0.6764 - val_accuracy: 0.5148\n",
      "Epoch 49/50\n",
      "102/101 [==============================] - 252s 2s/step - loss: 0.6608 - accuracy: 0.5627 - val_loss: 0.7069 - val_accuracy: 0.5049\n",
      "Epoch 50/50\n",
      "102/101 [==============================] - 250s 2s/step - loss: 0.6581 - accuracy: 0.5652 - val_loss: 0.6532 - val_accuracy: 0.5803\n",
      "\n",
      "try_Xception trained! Training time = 84.93429055913336 min!\n",
      "\n",
      "Total training time = 1.415571563503611 hr!\n"
     ]
    }
   ],
   "source": [
    "if TrainFullModel:\n",
    "    Start=time.perf_counter()\n",
    "    ModelKeys=list(models.keys())\n",
    "    for ModelKey in ModelKeys:\n",
    "        ModelStart=time.perf_counter()\n",
    "        print('\\nTraining '+str(ModelKey)+'...')\n",
    "        Model_Path = os.path.join(MasterPath,str(ModelKey))\n",
    "        model = models[ModelKey]\n",
    "        \n",
    "        train_model (model, X_Train=X_Train, Y_Train=Y_Train, X_Val=X_Val, Y_Val=Y_Val, \n",
    "                     batch_size=16, initial_epoch=30, final_epoch=50,\n",
    "                     Model_Path=Model_Path, shuffle=True, DatagenShuffleSeed=None)\n",
    "        \n",
    "        print('\\n'+str(ModelKey)+' trained! Training time = '+ str((time.perf_counter()-ModelStart)/60) + ' min!')\n",
    "    print('\\nTotal training time = '+ str((time.perf_counter()-Start)/(60*60)) + ' hr!')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models =  1\n",
      "Train Loss and Accuracy\n",
      "try_Xception : [0.6654084621027093, 0.5590406]\n",
      "\n",
      "Val Loss and Accuracy\n",
      "try_Xception : [0.6532389177650701, 0.58032787]\n",
      "\n",
      "Test Loss and Accuracy\n",
      "try_Xception : [0.6721103425119438, 0.51960784]\n"
     ]
    }
   ],
   "source": [
    "print ('Total number of models = ',str(len(models.keys())))\n",
    "print ('Train Loss and Accuracy')\n",
    "TrainEval=[]\n",
    "ModelKeys=list(models.keys())\n",
    "for ModelKey in ModelKeys:\n",
    "    Eval=models[ModelKey].evaluate(X_Train,Y_Train, verbose=0)\n",
    "    TrainEval.append(str(ModelKey)+' : '+str(Eval))\n",
    "print ('\\n'.join(TrainEval)) \n",
    "\n",
    "print ('\\nVal Loss and Accuracy')\n",
    "ValEval=[]\n",
    "for ModelKey in ModelKeys:\n",
    "    Eval=models[ModelKey].evaluate(X_Val,Y_Val, verbose=0)\n",
    "    ValEval.append(str(ModelKey)+' : '+str(Eval))\n",
    "print ('\\n'.join(ValEval)) \n",
    "\n",
    "print ('\\nTest Loss and Accuracy')\n",
    "TestEval=[]\n",
    "for ModelKey in ModelKeys:\n",
    "    Eval=models[ModelKey].evaluate(X_Test,Y_Test, verbose=0)\n",
    "    TestEval.append(str(ModelKey)+' : '+str(Eval))\n",
    "print ('\\n'.join(TestEval)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the latest version of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving try_Xception\n",
      "WARNING:tensorflow:From C:\\Users\\biejds\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: \\\\kuehlapis.mbi.nus.edu.sg\\home\\jokhun\\try_Xception\\LatestModel\\assets\n",
      "\n",
      "The latest version of each model has been saved!\n"
     ]
    }
   ],
   "source": [
    "SaveLatestVersions = True\n",
    "if SaveLatestVersions:\n",
    "    \n",
    "    for ModelKey in ModelKeys:\n",
    "        print('\\nSaving '+str(ModelKey))\n",
    "        Save_Path = os.path.join(MasterPath,str(ModelKey),\"LatestModel\")\n",
    "        models[ModelKey].save(\n",
    "            Save_Path, overwrite=False, include_optimizer=True, save_format=None,\n",
    "            signatures=None, options=None\n",
    "        )\n",
    "    print('\\nThe latest version of each model has been saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
