{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataPartition import DataPartition\n",
    "from im_import import Import_GrayImg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import ModifiedModels\n",
    "import os\n",
    "import sys\n",
    "from RegularizeModel import RegularizeModel\n",
    "from SaveModelDescript import SaveModelDescript\n",
    "from ModelEditor import ModelEditor\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the input X and Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes available :\n",
      " ['0_DMSO_Complete', 'DMSO', 'caffeine', 'chlorphenamine', 'estradiol', 'paracetamol']\n"
     ]
    }
   ],
   "source": [
    "# MasterPath = os.path.abspath(\"/gpfs0/home/jokhun/\")\n",
    "MasterPath = os.path.abspath('//fs9.nus.edu.sg/bie/MBELab/jokhun/Pro 1/U2OS small mol screening')\n",
    "\n",
    "Segmented_MasterFolder = 'Segmented_SmallMol'\n",
    "\n",
    "Classes = sorted([Class for Class in os.listdir(os.path.join(MasterPath,Segmented_MasterFolder)) \n",
    "           if os.path.isdir(os.path.join(MasterPath,Segmented_MasterFolder,Class))])\n",
    "print('Classes available :\\n',Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the following cell to select specific classes rather than all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes selected :\n",
      " ['DMSO', 'estradiol']\n",
      "No. of Images available =  7982\n",
      "DMSO  :  6000\n",
      "estradiol  :  1982\n"
     ]
    }
   ],
   "source": [
    "Select_Classes = True # Set to False in order to select all available classes\n",
    "selection = [1,4] # List of classes to be selected. Only used if Select_Classes is True\n",
    "\n",
    "if Select_Classes:\n",
    "    Selected_Classes = list(operator.itemgetter(*selection)(Classes))\n",
    "else:\n",
    "    Selected_Classes = Classes\n",
    "\n",
    "ClassPaths={}\n",
    "for Class in Selected_Classes:\n",
    "    ClassPaths[Class]=sorted(glob.glob(os.path.join(\n",
    "        MasterPath,Segmented_MasterFolder,Class,f\"*_{Class}.tif\"\n",
    "    )))\n",
    "\n",
    "print('Classes selected :\\n',Selected_Classes)\n",
    "print('No. of Images available = ', np.sum([len(ClassPaths[Class]) for Class in ClassPaths]))\n",
    "for Class in ClassPaths: print (Class,' : ',len(ClassPaths[Class]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Paths selected =  256\n",
      "DMSO  :  128\n",
      "estradiol  :  128\n"
     ]
    }
   ],
   "source": [
    "# Using the smallest dataset to determine the number of images to import from each class\n",
    "MinDatasetSizes=128 #np.amin([len(items[1]) for items in ClassPaths.items()])\n",
    "np.random.seed(0)\n",
    "\n",
    "for Class in ClassPaths.keys():\n",
    "    ClassPaths[Class]=sorted(np.random.choice(ClassPaths[Class], \n",
    "                                              size = MinDatasetSizes, replace = False))\n",
    "XPaths = []\n",
    "for Class in ClassPaths.keys():\n",
    "    XPaths.extend(ClassPaths[Class])\n",
    "\n",
    "print('No. of Paths selected = ', len(XPaths))\n",
    "for Class in ClassPaths: print (Class,' : ',len(ClassPaths[Class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partitioning data X and creating labels Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paths = 256\n",
      "Length of Training Set = 205\n",
      "Classes in Training Set : ['DMSO' 'estradiol'] --- Frequencies : [105 100]\n",
      "Length of Validation Set = 39\n",
      "Classes in Validation Set : ['DMSO' 'estradiol'] --- Frequencies : [16 23]\n",
      "Length of Test Set = 12\n",
      "Classes in Test Set : ['DMSO' 'estradiol'] --- Frequencies : [7 5]\n",
      "\n",
      "1st element of Training Set : estradiol\n",
      "\\\\fs9.nus.edu.sg\\bie\\MBELab\\jokhun\\Pro 1\\U2OS small mol screening\\Segmented_SmallMol\\estradiol\\24294_i02_s6_22_estradiol.tif\n",
      "1st element of Validation Set : DMSO\n",
      "\\\\fs9.nus.edu.sg\\bie\\MBELab\\jokhun\\Pro 1\\U2OS small mol screening\\Segmented_SmallMol\\DMSO\\25988_d11_s1_2_DMSO.tif\n",
      "1st element of Test Set : DMSO\n",
      "\\\\fs9.nus.edu.sg\\bie\\MBELab\\jokhun\\Pro 1\\U2OS small mol screening\\Segmented_SmallMol\\DMSO\\24307_d11_s3_11_DMSO.tif\n"
     ]
    }
   ],
   "source": [
    "# Y can be determined either from the filenames or the folders from which the images are loaded\n",
    "\n",
    "get_labels_from = 'folders' # 'Filenames' or 'Folders'\n",
    "\n",
    "Tr_Paths, Val_Paths, Ts_Paths = DataPartition(sorted(XPaths), \n",
    "                                              Partition=[0.8,0.15,0.05], RanSeed=0)\n",
    "\n",
    "if get_labels_from.lower() == 'filenames':\n",
    "    Tr_Y = [path[path.rindex('_') + 1 : path.index('.tif')] for path in Tr_Paths]\n",
    "    Val_Y = [path[path.rindex('_') + 1 : path.index('.tif')] for path in Val_Paths]\n",
    "    Ts_Y = [path[path.rindex('_') + 1 : path.index('.tif')] for path in Ts_Paths]\n",
    "\n",
    "elif get_labels_from.lower() == 'folders':\n",
    "    Tr_Y = [os.path.basename(os.path.dirname(path)) for path in Tr_Paths]\n",
    "    Val_Y = [os.path.basename(os.path.dirname(path)) for path in Val_Paths]\n",
    "    Ts_Y = [os.path.basename(os.path.dirname(path)) for path in Ts_Paths]\n",
    "    \n",
    "else: sys.exit(\"Invalid entry for 'get_labels_from'!\")\n",
    "\n",
    "print ('Total number of paths = ' + str(len(Tr_Paths)+len(Val_Paths)+len(Ts_Paths)))\n",
    "print ('Length of Training Set = ' + str(len(Tr_Paths)))\n",
    "values, counts = np.unique(Tr_Y, return_counts=True)\n",
    "print ('Classes in Training Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "print ('Length of Validation Set = ' + str(len(Val_Paths)))\n",
    "values, counts = np.unique(Val_Y, return_counts=True)\n",
    "print ('Classes in Validation Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "print ('Length of Test Set = ' + str(len(Ts_Paths)))\n",
    "values, counts = np.unique(Ts_Y, return_counts=True)\n",
    "print ('Classes in Test Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "\n",
    "print (f'\\n1st element of Training Set : {Tr_Y[0]}\\n' + str(Tr_Paths[0]))\n",
    "print (f'1st element of Validation Set : {Val_Y[0]}\\n' + str(Val_Paths[0]))\n",
    "print (f'1st element of Test Set : {Ts_Y[0]}\\n' + str(Ts_Paths[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import images: Tr_X, Val_X and Ts_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed during import = 2.4377695600000013 s\n",
      "Length of Training Set = 205\n",
      "Length of Validation Set = 39\n",
      "Length of Test Set = 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Text(0.5, 1.0, 'Test[0]'), <matplotlib.image.AxesImage at 0x12ac7682548>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ImgScaleFactor = 4\n",
    "DesiredImgSize = 224\n",
    "\n",
    "start=time.perf_counter()\n",
    "with mp.Pool() as pool:\n",
    "    Tr_X = pool.starmap(Import_GrayImg, [(path,ImgScaleFactor,DesiredImgSize) for path in Tr_Paths])\n",
    "    Val_X = pool.starmap(Import_GrayImg, [(path,ImgScaleFactor,DesiredImgSize) for path in Val_Paths])\n",
    "    Ts_X = pool.starmap(Import_GrayImg, [(path,ImgScaleFactor,DesiredImgSize) for path in Ts_Paths])\n",
    "print('Time elapsed during import = '+ str(time.perf_counter() - start) + ' s')\n",
    "\n",
    "print ('Length of Training Set = '+str(len(Tr_X)))\n",
    "print ('Length of Validation Set = '+str(len(Val_X)))\n",
    "print ('Length of Test Set = '+str(len(Ts_X)))\n",
    "\n",
    "plt.subplot(1,3,1).set_title('Train[0]'), plt.imshow(Tr_X[0], cmap='gray', norm=matplotlib.colors.Normalize())\n",
    "plt.subplot(1,3,2).set_title('Val[0]'), plt.imshow(Val_X[0], cmap='gray', norm=matplotlib.colors.Normalize())\n",
    "plt.subplot(1,3,3).set_title('Test[0]'), plt.imshow(Ts_X[0], cmap='gray', norm=matplotlib.colors.Normalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of invalid files = 0\n",
      "Classes in Training Set : ['DMSO' 'estradiol'] --- Frequencies : [105 100]\n",
      "Classes in Validation Set : ['DMSO' 'estradiol'] --- Frequencies : [16 23]\n",
      "Classes in Test Set : ['DMSO' 'estradiol'] --- Frequencies : [7 5]\n",
      "\n",
      "Invalid Traininig files = 0\n",
      "[]\n",
      "\n",
      "Invalid Val files = 0\n",
      "[]\n",
      "\n",
      "Invalid Test files = 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Getting rid of invalid images (if th enucleus was too large to fit within 'DesiredImgSize')\n",
    "Invalid_Tr = [i for i,val in enumerate(Tr_X) if type(val)==type(None)]\n",
    "for idx in sorted(Invalid_Tr, reverse=True):\n",
    "    del Tr_X[idx]\n",
    "    del Tr_Y[idx]\n",
    "\n",
    "Invalid_Val = [i for i,val in enumerate(Val_X) if type(val)==type(None)]\n",
    "for idx in sorted(Invalid_Val, reverse=True):\n",
    "    del Val_X[idx]\n",
    "    del Val_Y[idx]\n",
    "\n",
    "Invalid_Ts = [i for i,val in enumerate(Ts_X) if type(val)==type(None)]\n",
    "for idx in sorted(Invalid_Ts, reverse=True):\n",
    "    del Ts_X[idx]\n",
    "    del Ts_Y[idx]\n",
    "\n",
    "print ('Total number of invalid files = '+str(len(Invalid_Tr)+len(Invalid_Val)+len(Invalid_Ts)))\n",
    "values, counts = np.unique(Tr_Y, return_counts=True)\n",
    "print ('Classes in Training Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "values, counts = np.unique(Val_Y, return_counts=True)\n",
    "print ('Classes in Validation Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "values, counts = np.unique(Ts_Y, return_counts=True)\n",
    "print ('Classes in Test Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "\n",
    "print('\\nInvalid Traininig files = '+str(len(Invalid_Tr))+'\\n'+str(operator.itemgetter(Invalid_Tr)(Tr_Paths)))\n",
    "print('\\nInvalid Val files = '+str(len(Invalid_Val))+'\\n'+str(operator.itemgetter(Invalid_Val)(Val_Paths)))\n",
    "print('\\nInvalid Test files = '+str(len(Invalid_Ts))+'\\n'+str(operator.itemgetter(Invalid_Ts)(Ts_Paths)))\n",
    "Tr_Paths = np.delete(Tr_Paths,Invalid_Tr)\n",
    "Val_Paths = np.delete(Val_Paths,Invalid_Val)\n",
    "Ts_Paths = np.delete(Ts_Paths,Invalid_Ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restructuring the image dataset and encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train shape:(205, 224, 224, 1)   X_Val shape:(39, 224, 224, 1)   X_Test shape:(12, 224, 224, 1)\n",
      "Number of calsses in the data: 2\n",
      "Classes in the Data: ['DMSO' 'estradiol']\n",
      "1st element of Tr_Y, Val_Y and Ts_Y : estradiol, DMSO, DMSO\n",
      "1st element of Y_Train, Y_Val and Y_Test : 1, 0, 0\n"
     ]
    }
   ],
   "source": [
    "X_Train = tf.expand_dims(Tr_X, axis=-1)\n",
    "X_Val = tf.expand_dims(Val_X, axis=-1)\n",
    "X_Test = tf.expand_dims(Ts_X, axis=-1)\n",
    "print('X_Train shape:'+str(X_Train.shape) + '   X_Val shape:' + str(X_Val.shape) + '   X_Test shape:' + str(X_Test.shape))\n",
    "\n",
    "ResponseEncoder = LabelEncoder()\n",
    "ResponseEncoder.fit((Tr_Y + Val_Y + Ts_Y))\n",
    "NumOfClasses = len(ResponseEncoder.classes_)\n",
    "print('Number of calsses in the data: '+str(NumOfClasses))\n",
    "print('Classes in the Data: ' + str(ResponseEncoder.classes_))\n",
    "Y_Train = ResponseEncoder.transform(Tr_Y)\n",
    "Y_Val = ResponseEncoder.transform(Val_Y)\n",
    "Y_Test = ResponseEncoder.transform(Ts_Y)\n",
    "print ('1st element of Tr_Y, Val_Y and Ts_Y : ' + str(Tr_Y[0]) + ', ' + str(Val_Y[0]) + ', ' + str(Ts_Y[0]))\n",
    "print ('1st element of Y_Train, Y_Val and Y_Test : ' + str(Y_Train[0]) + ', ' + str(Y_Val[0]) + ', ' + str(Y_Test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the untrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  model/s created!\n"
     ]
    }
   ],
   "source": [
    "CreateModel = True\n",
    "\n",
    "models = {}\n",
    "\n",
    "if CreateModel:\n",
    "#     models['mod_NASNetLarge_ori'] = ModifiedModels.mod_NASNetLarge(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1])\n",
    "    models['mod_Xception_try'] = ModifiedModels.mod_Xception(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1])\n",
    "#     models['mod_InceptionResNetV2_ori'] = ModifiedModels.mod_InceptionResNetV2(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1])\n",
    "#     models['mod_InceptionV3_ori'] = ModifiedModels.mod_InceptionV3(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1])\n",
    "#     models['mod_VGG19_ori'] = ModifiedModels.mod_VGG19(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1])\n",
    "#     models['mod_ResNet50V2_ori'] = ModifiedModels.mod_ResNet50V2(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1])\n",
    "#     models['mod_VGG16_ori'] = ModifiedModels.mod_VGG16(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1])\n",
    "#     models['mod_ResNet50_ori'] = ModifiedModels.mod_ResNet50(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1])\n",
    "    \n",
    "    ModelsCreated = len(models.keys())\n",
    "    print (str(ModelsCreated),' model/s created!')\n",
    "else:\n",
    "    print ('No model created. Load one from disk below!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model loaded from disk!\n"
     ]
    }
   ],
   "source": [
    "LoadModelFromDisk = False\n",
    "\n",
    "if LoadModelFromDisk:\n",
    "    models['mdl_name'] = tf.keras.models.load_model('mdl_path')\n",
    "    \n",
    "    ModelsLoaded = len(models.keys()) - ModelsCreated\n",
    "    print (str(ModelsLoaded),' models loaded from disk!')\n",
    "else:\n",
    "    print ('No model loaded from disk!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models =  1\n",
      "Initial Test Loss and Accuracy\n",
      "mod_Xception_try : [0.6931468844413757, 0.5833333]\n"
     ]
    }
   ],
   "source": [
    "ModelKeys=list(models.keys())\n",
    "\n",
    "print ('Total number of models = ',str(len(models.keys())))\n",
    "print ('Initial Test Loss and Accuracy')\n",
    "InitialEval=[]\n",
    "for ModelKey in ModelKeys:\n",
    "    eval=models[ModelKey].evaluate(X_Test,Y_Test, verbose=0)\n",
    "    InitialEval.append(str(ModelKey)+' : '+str(eval))\n",
    "print ('\\n'.join(InitialEval)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model descriptions saved!\n"
     ]
    }
   ],
   "source": [
    "# Save model description\n",
    "SaveModelDescription = True\n",
    "\n",
    "if SaveModelDescription:\n",
    "    for ModelKey in ModelKeys:\n",
    "        model = models[ModelKey]\n",
    "        Model_Path = os.path.join(MasterPath,str(ModelKey))        \n",
    "        SaveModelDescript(model, save_dir=Model_Path, \n",
    "                          save_filename=str(ModelKey))        \n",
    "    print ('Model descriptions saved!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile_args did not work. getattr was used instead.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Input layer/s has/have to be instance/s of tf.keras.layers.Layer!)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-c4816c268b1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     model = ModelEditor(model, New_Layers=New_Layers, IncomingLinks_2Axe=IncomingLinks_2Axe, \n\u001b[0;32m     32\u001b[0m                                 \u001b[0mIncomingLinks_2Forge\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mIncomingLinks_2Forge\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                                 model_inputs=model_inputs, model_outputs=model_outputs)\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mModelKeys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Cloud\\Google Drive\\Codes\\GitHub_LabPC\\CommonDeepConvNeuNet\\ModelEditor.py\u001b[0m in \u001b[0;36mModelEditor\u001b[1;34m(model, New_Layers, IncomingLinks_2Axe, IncomingLinks_2Forge, model_inputs, model_outputs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mreconnect_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreorder_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Cloud\\Google Drive\\Codes\\GitHub_LabPC\\CommonDeepConvNeuNet\\reconnect_layers.py\u001b[0m in \u001b[0;36mreconnect_layers\u001b[1;34m(obj, input_layers, reorder_layers)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mlist\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0minput_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minput_layers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_layer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Input layer/s has/have to be instance/s of tf.keras.layers.Layer!)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#         Obtaining the layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Input layer/s has/have to be instance/s of tf.keras.layers.Layer!)"
     ]
    }
   ],
   "source": [
    "Edit_Model = True\n",
    "\n",
    "if Edit_Model:\n",
    "    model = models[ModelKeys[0]]\n",
    "\n",
    "    New_Layers={'drop1':tf.keras.layers.Dropout(rate=0.1, name='drop1'),\n",
    "                'drop2':tf.keras.layers.Dropout(rate=0.2, name='drop2'),\n",
    "                'drop3':tf.keras.layers.Dropout(rate=0.3, name='drop3'),\n",
    "                'drop4':tf.keras.layers.Dropout(rate=0.4, name='drop4'),\n",
    "                'drop5':tf.keras.layers.Dropout(rate=0.5, name='drop5'),\n",
    "               }\n",
    "\n",
    "    IncomingLinks_2Axe=[-18, -12, -14, -8, -5, -1]   \n",
    "\n",
    "    IncomingLinks_2Forge=[(New_Layers['drop1'], model.layers[-19]),\n",
    "                          (model.layers[-18], New_Layers['drop1']),\n",
    "                          (model.layers[-12], New_Layers['drop1']),\n",
    "                          (New_Layers['drop2'], model.layers[-15]),\n",
    "                          (model.layers[-14], New_Layers['drop2']),\n",
    "                          (New_Layers['drop3'], model.layers[-9]),\n",
    "                          (model.layers[-8], New_Layers['drop3']),\n",
    "                          (New_Layers['drop4'], model.layers[-6]),\n",
    "                          (model.layers[-5], New_Layers['drop4']),\n",
    "                          (New_Layers['drop5'], model.layers[-2]),\n",
    "                          (model.layers[-1], New_Layers['drop5']),\n",
    "                         ]\n",
    "\n",
    "    model_inputs=None\n",
    "    model_outputs=None\n",
    "\n",
    "    model = ModelEditor(model, New_Layers=New_Layers, IncomingLinks_2Axe=IncomingLinks_2Axe, \n",
    "                                IncomingLinks_2Forge=IncomingLinks_2Forge,\n",
    "                                model_inputs=model_inputs, model_outputs=model_outputs)\n",
    "\n",
    "    models[ModelKeys[0]] = model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save edited model description\n",
    "SaveEditedModelDescription = True\n",
    "\n",
    "if Edit_Model and SaveEditedModelDescription:\n",
    "    for ModelKey in ModelKeys:\n",
    "        model = models[ModelKey]\n",
    "        Model_Path = os.path.join(MasterPath,str(ModelKey))        \n",
    "        SaveModelDescript(model, save_dir=Model_Path, \n",
    "                          save_filename=str(ModelKey+'_edited'))        \n",
    "    print ('Model descriptions saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Regularization to all regularizable layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegularizeTheModel = True\n",
    "if RegularizeTheModel:\n",
    "    regularizer = tf.keras.regularizers.l1_l2(l1=0, l2=0.1)\n",
    "    for ModelKey in ModelKeys:\n",
    "        models[ModelKey]=RegularizeModel(models[ModelKey], regularizer, keep_weights=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UseImageDataGenerator = False\n",
    "\n",
    "def ImgGrayscale (img):\n",
    "    bw = img>0\n",
    "    img = np.subtract(img, np.amin(img))\n",
    "    img = np.divide(img, np.amax(img))\n",
    "    img = img*bw   \n",
    "    return img\n",
    "\n",
    "if UseImageDataGenerator:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.0,\n",
    "        height_shift_range=0.0,\n",
    "        brightness_range=None,\n",
    "        shear_range=0.0,\n",
    "        zoom_range=0.0,\n",
    "        channel_shift_range=0.0,\n",
    "        fill_mode=\"constant\",\n",
    "        cval=0,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rescale=None,\n",
    "        preprocessing_function=ImgGrayscale,\n",
    "        data_format=None,\n",
    "        validation_split=0.0,\n",
    "        dtype=None,\n",
    "    )\n",
    "else:\n",
    "    datagen = ImageDataGenerator(preprocessing_function=ImgGrayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the models, saving modelcheckpoints and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=64; initial_epoch=0; final_epoch=50; DatagenShuffleSeed=0;\n",
    "\n",
    "Start=time.perf_counter()\n",
    "for ModelKey in ModelKeys:\n",
    "    ModelStart=time.perf_counter()\n",
    "    print('\\nTraining '+str(ModelKey)+'...')\n",
    "        \n",
    "    Model_Path = os.path.join(MasterPath,str(ModelKey))\n",
    "    \n",
    "    MdlChkpt_Path = os.path.join(Model_Path,\"MdlChkpt\",\"e{epoch:03d}_Acc{accuracy:.2f}_ValAcc{val_accuracy:.2f}.ckpt\")\n",
    "    MdlChkpt_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        MdlChkpt_Path, monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=True, \n",
    "        mode='auto', save_freq=\"epoch\"\n",
    "    )\n",
    "    TensorBoard_Path = os.path.join(Model_Path,\"logs\")\n",
    "    TensorBoard_cb = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir = TensorBoard_Path, histogram_freq=0, write_graph=False, write_images=False, update_freq=\"epoch\", \n",
    "        profile_batch=0, embeddings_freq=0, embeddings_metadata=None\n",
    "    )\n",
    "    \n",
    "#     try:\n",
    "#         initial_epoch = models[ModelKey]._maybe_load_initial_epoch_from_ckpt(final_epoch, 'mode')\n",
    "#     except:\n",
    "#         initial_epoch = 0 \n",
    "#     final_epoch = initial_epoch + Epochs2TrainFor\n",
    "    \n",
    "    models[ModelKey].fit(\n",
    "        datagen.flow(x=X_Train, y=Y_Train, batch_size=batch_size,shuffle=False,sample_weight=None,seed=DatagenShuffleSeed,\n",
    "                     save_to_dir=None,save_prefix=\"\",save_format=\"png\",subset=None), \n",
    "        initial_epoch=initial_epoch, epochs=final_epoch, steps_per_epoch=len(X_Train)/batch_size, \n",
    "        verbose=1, callbacks=[MdlChkpt_cb, TensorBoard_cb], \n",
    "        validation_data=(X_Val,Y_Val), shuffle=False, use_multiprocessing=True\n",
    "    )\n",
    "       \n",
    "    print('\\n'+str(ModelKey)+' trained! Training time = '+ str((time.perf_counter()-ModelStart)/60) + ' min!')\n",
    "    print('Test Loss and Accuracy [Initial] [Final]')\n",
    "    for i,ModelKey in enumerate(ModelKeys):\n",
    "        eval=models[ModelKey].evaluate(X_Test,Y_Test, verbose=0)\n",
    "        print(InitialEval[i]+' '+str(eval))\n",
    "print('\\nTotal training time = '+ str((time.perf_counter()-Start)/(60*60)) + ' hr!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelKeys=list(models.keys())\n",
    "\n",
    "print ('Total number of models = ',str(len(models.keys())))\n",
    "print ('Initial Train Loss and Accuracy')\n",
    "InitialEval=[]\n",
    "for ModelKey in ModelKeys:\n",
    "    eval=models[ModelKey].evaluate(X_Train,Y_Train, verbose=0)\n",
    "    InitialEval.append(str(ModelKey)+' : '+str(eval))\n",
    "print ('\\n'.join(InitialEval)) \n",
    "\n",
    "print ('\\nInitial Val Loss and Accuracy')\n",
    "InitialEval=[]\n",
    "for ModelKey in ModelKeys:\n",
    "    eval=models[ModelKey].evaluate(X_Val,Y_Val, verbose=0)\n",
    "    InitialEval.append(str(ModelKey)+' : '+str(eval))\n",
    "print ('\\n'.join(InitialEval)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl=models[list(models.keys())[0]]\n",
    "print(mdl.layers[2].losses)\n",
    "mdl.layers[2].get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the latest version of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ModelKey in ModelKeys:\n",
    "    print('\\nSaving '+str(ModelKey))\n",
    "    Save_Path = os.path.join(MasterPath,str(ModelKey),\"LatestModel\")\n",
    "    models[ModelKey].save(\n",
    "        Save_Path, overwrite=False, include_optimizer=True, save_format=None,\n",
    "        signatures=None, options=None\n",
    "    )\n",
    "print('\\nThe latest version of each model has been saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
