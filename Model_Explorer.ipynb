{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataPartition import DataPartition\n",
    "from im_import import Import_GrayImg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import ModifiedModels\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the input X and Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes available :\n",
      " ['0_DMSO_Complete', 'DMSO', 'caffeine', 'chlorphenamine', 'estradiol', 'paracetamol']\n"
     ]
    }
   ],
   "source": [
    "# MasterPath = os.path.abspath(\"/gpfs0/home/jokhun/\")\n",
    "\n",
    "MasterPath = os.path.abspath('//fs9.nus.edu.sg/bie/MBELab/jokhun/Pro 1/U2OS small mol screening')\n",
    "Segmented_MasterFolder = 'Segmented_SmallMol'\n",
    "\n",
    "Classes = sorted([Class for Class in os.listdir(os.path.join(MasterPath,Segmented_MasterFolder)) \n",
    "           if os.path.isdir(os.path.join(MasterPath,Segmented_MasterFolder,Class))])\n",
    "print('Classes available :\\n',Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the following cell to select specific classes rather than all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes selected :\n",
      " ['DMSO', 'estradiol']\n",
      "No. of Images available =  7982\n",
      "DMSO  :  6000\n",
      "estradiol  :  1982\n"
     ]
    }
   ],
   "source": [
    "Select_Classes = True # Set to False in order to select all available classes\n",
    "selection = [1,4] # List of classes to be selected. Only used if Select_Classes is True\n",
    "\n",
    "if Select_Classes:\n",
    "    Selected_Classes = list(operator.itemgetter(*selection)(Classes))\n",
    "else:\n",
    "    Selected_Classes = Classes\n",
    "\n",
    "ClassPaths={}\n",
    "for Class in Selected_Classes:\n",
    "    ClassPaths[Class]=sorted(glob.glob(os.path.join(\n",
    "        MasterPath,Segmented_MasterFolder,Class,f\"*_{Class}.tif\"\n",
    "    )))\n",
    "\n",
    "print('Classes selected :\\n',Selected_Classes)\n",
    "print('No. of Images available = ', np.sum([len(ClassPaths[Class]) for Class in ClassPaths]))\n",
    "for Class in ClassPaths: print (Class,' : ',len(ClassPaths[Class]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Paths selected =  256\n",
      "DMSO  :  128\n",
      "estradiol  :  128\n"
     ]
    }
   ],
   "source": [
    "# Using the smallest dataset to determine the number of images to import from each class\n",
    "MinDatasetSizes=128#np.amin([len(items[1]) for items in ClassPaths.items()])\n",
    "np.random.seed(0)\n",
    "\n",
    "for Class in ClassPaths.keys():\n",
    "    ClassPaths[Class]=sorted(np.random.choice(ClassPaths[Class], \n",
    "                                              size = MinDatasetSizes, replace = False))\n",
    "XPaths = []\n",
    "for Class in ClassPaths.keys():\n",
    "    XPaths.extend(ClassPaths[Class])\n",
    "\n",
    "print('No. of Paths selected = ', len(XPaths))\n",
    "for Class in ClassPaths: print (Class,' : ',len(ClassPaths[Class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partitioning data X and creating labels Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paths = 244\n",
      "Length of Training Set = 205\n",
      "Classes in Training Set : ['DMSO' 'estradiol'] --- Frequencies : [105 100]\n",
      "Length of Validation Set = 26\n",
      "Classes in Validation Set : ['DMSO' 'estradiol'] --- Frequencies : [10 16]\n",
      "Length of Test Set = 13\n",
      "Classes in Test Set : ['DMSO' 'estradiol'] --- Frequencies : [6 7]\n",
      "\n",
      "1st element of Training Set : estradiol\n",
      "\\\\fs9.nus.edu.sg\\bie\\MBELab\\jokhun\\Pro 1\\U2OS small mol screening\\Segmented_SmallMol\\estradiol\\24294_i02_s6_22_estradiol.tif\n",
      "1st element of Validation Set : DMSO\n",
      "\\\\fs9.nus.edu.sg\\bie\\MBELab\\jokhun\\Pro 1\\U2OS small mol screening\\Segmented_SmallMol\\DMSO\\25988_d11_s1_2_DMSO.tif\n",
      "1st element of Test Set : DMSO\n",
      "\\\\fs9.nus.edu.sg\\bie\\MBELab\\jokhun\\Pro 1\\U2OS small mol screening\\Segmented_SmallMol\\DMSO\\25938_m14_s2_20_DMSO.tif\n"
     ]
    }
   ],
   "source": [
    "# Y can be determined either from the filenames or the folders from which the images are loaded\n",
    "\n",
    "get_labels_from = 'folders' # 'Filenames' or 'Folders'\n",
    "\n",
    "Tr_Paths, Val_Paths, Ts_Paths = DataPartition(sorted(XPaths), \n",
    "                                              Partition=[0.8,0.10,0.05], RanSeed=0)\n",
    "\n",
    "if get_labels_from.lower() == 'filenames':\n",
    "    Tr_Y = [path[path.rindex('_') + 1 : path.index('.tif')] for path in Tr_Paths]\n",
    "    Val_Y = [path[path.rindex('_') + 1 : path.index('.tif')] for path in Val_Paths]\n",
    "    Ts_Y = [path[path.rindex('_') + 1 : path.index('.tif')] for path in Ts_Paths]\n",
    "\n",
    "elif get_labels_from.lower() == 'folders':\n",
    "    Tr_Y = [os.path.basename(os.path.dirname(path)) for path in Tr_Paths]\n",
    "    Val_Y = [os.path.basename(os.path.dirname(path)) for path in Val_Paths]\n",
    "    Ts_Y = [os.path.basename(os.path.dirname(path)) for path in Ts_Paths]\n",
    "    \n",
    "else: sys.exit(\"Invalid entry for 'get_labels_from'!\")\n",
    "\n",
    "print ('Total number of paths = ' + str(len(Tr_Paths)+len(Val_Paths)+len(Ts_Paths)))\n",
    "print ('Length of Training Set = ' + str(len(Tr_Paths)))\n",
    "values, counts = np.unique(Tr_Y, return_counts=True)\n",
    "print ('Classes in Training Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "print ('Length of Validation Set = ' + str(len(Val_Paths)))\n",
    "values, counts = np.unique(Val_Y, return_counts=True)\n",
    "print ('Classes in Validation Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "print ('Length of Test Set = ' + str(len(Ts_Paths)))\n",
    "values, counts = np.unique(Ts_Y, return_counts=True)\n",
    "print ('Classes in Test Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "\n",
    "print (f'\\n1st element of Training Set : {Tr_Y[0]}\\n' + str(Tr_Paths[0]))\n",
    "print (f'1st element of Validation Set : {Val_Y[0]}\\n' + str(Val_Paths[0]))\n",
    "print (f'1st element of Test Set : {Ts_Y[0]}\\n' + str(Ts_Paths[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import images: Tr_X, Val_X and Ts_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed during import = 6.790872016000321 s\n",
      "Length of Training Set = 205\n",
      "Length of Validation Set = 26\n",
      "Length of Test Set = 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Text(0.5, 1.0, 'Test[0]'), <matplotlib.image.AxesImage at 0x2d8b75b5128>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ImgScaleFactor = 4\n",
    "DesiredImgSize = 224\n",
    "\n",
    "start=time.perf_counter()\n",
    "with mp.Pool() as pool:\n",
    "    Tr_X = pool.starmap(Import_GrayImg, [(path,ImgScaleFactor,DesiredImgSize) for path in Tr_Paths])\n",
    "    Val_X = pool.starmap(Import_GrayImg, [(path,ImgScaleFactor,DesiredImgSize) for path in Val_Paths])\n",
    "    Ts_X = pool.starmap(Import_GrayImg, [(path,ImgScaleFactor,DesiredImgSize) for path in Ts_Paths])\n",
    "print('Time elapsed during import = '+ str(time.perf_counter() - start) + ' s')\n",
    "\n",
    "print ('Length of Training Set = '+str(len(Tr_X)))\n",
    "print ('Length of Validation Set = '+str(len(Val_X)))\n",
    "print ('Length of Test Set = '+str(len(Ts_X)))\n",
    "\n",
    "plt.subplot(1,3,1).set_title('Train[0]'), plt.imshow(Tr_X[0], cmap='gray', norm=matplotlib.colors.Normalize())\n",
    "plt.subplot(1,3,2).set_title('Val[0]'), plt.imshow(Val_X[0], cmap='gray', norm=matplotlib.colors.Normalize())\n",
    "plt.subplot(1,3,3).set_title('Test[0]'), plt.imshow(Ts_X[0], cmap='gray', norm=matplotlib.colors.Normalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of invalid files = 0\n",
      "Classes in Training Set : ['DMSO' 'estradiol'] --- Frequencies : [105 100]\n",
      "Classes in Validation Set : ['DMSO' 'estradiol'] --- Frequencies : [10 16]\n",
      "Classes in Test Set : ['DMSO' 'estradiol'] --- Frequencies : [6 7]\n",
      "\n",
      "Invalid Traininig files = 0\n",
      "[]\n",
      "\n",
      "Invalid Val files = 0\n",
      "[]\n",
      "\n",
      "Invalid Test files = 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Getting rid of invalid images (if th enucleus was too large to fit within 'DesiredImgSize')\n",
    "Invalid_Tr = [i for i,val in enumerate(Tr_X) if type(val)==type(None)]\n",
    "for idx in sorted(Invalid_Tr, reverse=True):\n",
    "    del Tr_X[idx]\n",
    "    del Tr_Y[idx]\n",
    "\n",
    "Invalid_Val = [i for i,val in enumerate(Val_X) if type(val)==type(None)]\n",
    "for idx in sorted(Invalid_Val, reverse=True):\n",
    "    del Val_X[idx]\n",
    "    del Val_Y[idx]\n",
    "\n",
    "Invalid_Ts = [i for i,val in enumerate(Ts_X) if type(val)==type(None)]\n",
    "for idx in sorted(Invalid_Ts, reverse=True):\n",
    "    del Ts_X[idx]\n",
    "    del Ts_Y[idx]\n",
    "\n",
    "print ('Total number of invalid files = '+str(len(Invalid_Tr)+len(Invalid_Val)+len(Invalid_Ts)))\n",
    "values, counts = np.unique(Tr_Y, return_counts=True)\n",
    "print ('Classes in Training Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "values, counts = np.unique(Val_Y, return_counts=True)\n",
    "print ('Classes in Validation Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "values, counts = np.unique(Ts_Y, return_counts=True)\n",
    "print ('Classes in Test Set : ' + str(values) + ' --- Frequencies : ' + str(counts))\n",
    "\n",
    "print('\\nInvalid Traininig files = '+str(len(Invalid_Tr))+'\\n'+str(operator.itemgetter(Invalid_Tr)(Tr_Paths)))\n",
    "print('\\nInvalid Val files = '+str(len(Invalid_Val))+'\\n'+str(operator.itemgetter(Invalid_Val)(Val_Paths)))\n",
    "print('\\nInvalid Test files = '+str(len(Invalid_Ts))+'\\n'+str(operator.itemgetter(Invalid_Ts)(Ts_Paths)))\n",
    "Tr_Paths = np.delete(Tr_Paths,Invalid_Tr)\n",
    "Val_Paths = np.delete(Val_Paths,Invalid_Val)\n",
    "Ts_Paths = np.delete(Ts_Paths,Invalid_Ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restructuring the image dataset and encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train shape:(205, 224, 224, 1)   X_Val shape:(26, 224, 224, 1)   X_Test shape:(13, 224, 224, 1)\n",
      "Number of calsses in the data: 2\n",
      "Classes in the Data: ['DMSO' 'estradiol']\n",
      "1st element of Tr_Y, Val_Y and Ts_Y : estradiol, DMSO, DMSO\n",
      "1st element of Y_Train, Y_Val and Y_Test : 1, 0, 0\n"
     ]
    }
   ],
   "source": [
    "X_Train = tf.expand_dims(Tr_X, axis=-1)\n",
    "X_Val = tf.expand_dims(Val_X, axis=-1)\n",
    "X_Test = tf.expand_dims(Ts_X, axis=-1)\n",
    "print('X_Train shape:'+str(X_Train.shape) + '   X_Val shape:' + str(X_Val.shape) + '   X_Test shape:' + str(X_Test.shape))\n",
    "\n",
    "ResponseEncoder = LabelEncoder()\n",
    "ResponseEncoder.fit((Tr_Y + Val_Y + Ts_Y))\n",
    "NumOfClasses = len(ResponseEncoder.classes_)\n",
    "print('Number of calsses in the data: '+str(NumOfClasses))\n",
    "print('Classes in the Data: ' + str(ResponseEncoder.classes_))\n",
    "Y_Train = ResponseEncoder.transform(Tr_Y)\n",
    "Y_Val = ResponseEncoder.transform(Val_Y)\n",
    "Y_Test = ResponseEncoder.transform(Ts_Y)\n",
    "print ('1st element of Tr_Y, Val_Y and Ts_Y : ' + str(Tr_Y[0]) + ', ' + str(Val_Y[0]) + ', ' + str(Ts_Y[0]))\n",
    "print ('1st element of Y_Train, Y_Val and Y_Test : ' + str(Y_Train[0]) + ', ' + str(Y_Val[0]) + ', ' + str(Y_Test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the untrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Test Loss and Accuracy\n",
      "mod_Xception_try : [0.6931473612785339, 0.46153846]\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "#     'mod_NASNetLarge' : ModifiedModels.mod_NASNetLarge(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "    'mod_Xception_try' : ModifiedModels.mod_Xception(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "#     'mod_InceptionResNetV2' : ModifiedModels.mod_InceptionResNetV2(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "#     'mod_InceptionV3' : ModifiedModels.mod_InceptionV3(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "#     'mod_VGG19' : ModifiedModels.mod_VGG19(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "#     'mod_ResNet50V2' : ModifiedModels.mod_ResNet50V2(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "#     'mod_VGG16' : ModifiedModels.mod_VGG16(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]), \n",
    "#     'mod_ResNet50' : ModifiedModels.mod_ResNet50(NumOfClasses=NumOfClasses, NumOfInputCh=X_Train.shape[-1], ImgSize=X_Train.shape[1]),\n",
    "}\n",
    "\n",
    "ModelKeys=list(models.keys())\n",
    "\n",
    "print('Initial Test Loss and Accuracy')\n",
    "InitialEval=[]\n",
    "for ModelKey in ModelKeys:\n",
    "    eval=models[ModelKey].evaluate(X_Test,Y_Test, verbose=0)\n",
    "    InitialEval.append(str(ModelKey)+' : '+str(eval))\n",
    "print ('\\n'.join(InitialEval)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Regularization to all regularizable layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "def add_regularization(model, regularizer):\n",
    "    \n",
    "    if not isinstance(regularizer, tf.keras.regularizers.Regularizer):\n",
    "        print(\"Regularizer must be a subclass of tf.keras.regularizers.Regularizer\")\n",
    "        return model\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel_regularizer'):\n",
    "            setattr(layer, 'kernel_regularizer', regularizer)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=model.inputs, outputs=model.outputs, name=model.name)\n",
    "\n",
    "\n",
    "\n",
    "    # When we change the layers attributes, the change only happens in the model config file\n",
    "    tmp_weights_path = f'tmp_weights_{random.randint(10000,100000)}.h5'\n",
    "    model.save_weights(tmp_weights_path) # Save the weights before reloading the model.\n",
    "    model = tf.keras.models.Model.from_config(model.get_config()) # recreates the model from the altered config file\n",
    "    model.load_weights(tmp_weights_path, by_name=True) # Reload the model weights\n",
    "    os.remove(tmp_weights_path)\n",
    "    \n",
    "    model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = tf.keras.regularizers.l1_l2(l1=0, l2=0)\n",
    "for ModelKey in ModelKeys:\n",
    "    models[ModelKey]=add_regularization(models[ModelKey], regularizer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Displaying model description\n",
    "# model2view = 0 \n",
    "\n",
    "# mdl = models[ModelKeys[model2view]]\n",
    "# # mdl.summary()\n",
    "# # plot_model(mdl, to_file=f\"{list(models.keys())[model2view]}.png\", \n",
    "# #            show_shapes=True, show_layer_names=True, rankdir=\"TB\", expand_nested=True, dpi=96)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImgGrayscale (img):\n",
    "    bw = img>0\n",
    "    img = np.subtract(img, np.amin(img))\n",
    "    img = np.divide(img, np.amax(img))\n",
    "    img = img*bw   \n",
    "    return img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.0,\n",
    "    height_shift_range=0.0,\n",
    "    brightness_range=None,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.0,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode=\"constant\",\n",
    "    cval=0,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=None,\n",
    "    preprocessing_function=ImgGrayscale,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the models, saving modelcheckpoints and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training mod_Xception_try...\n",
      "Train for 3.203125 steps, validate on 26 samples\n",
      "Epoch 1/5\n",
      "4/3 [=====================================] - 64s 16s/step - loss: 0.8427 - accuracy: 0.5415 - val_loss: 0.6910 - val_accuracy: 0.6154\n",
      "Epoch 2/5\n",
      "4/3 [=====================================] - 5s 1s/step - loss: 0.7435 - accuracy: 0.5268 - val_loss: 0.6906 - val_accuracy: 0.6154\n",
      "Epoch 3/5\n",
      "4/3 [=====================================] - 5s 1s/step - loss: 0.7886 - accuracy: 0.4683 - val_loss: 0.6915 - val_accuracy: 0.6154\n",
      "Epoch 4/5\n",
      "4/3 [=====================================] - 7s 2s/step - loss: 0.7567 - accuracy: 0.5610 - val_loss: 0.6917 - val_accuracy: 0.6154\n",
      "Epoch 5/5\n",
      "4/3 [=====================================] - 5s 1s/step - loss: 0.8165 - accuracy: 0.4878 - val_loss: 0.6907 - val_accuracy: 0.6154\n",
      "\n",
      "mod_Xception_try trained! Training time = 1.458817931616674 min!\n",
      "Test Loss and Accuracy [Initial] [Final]\n",
      "mod_Xception_try : [0.6931473612785339, 0.46153846] [0.6923761963844299, 0.53846157]\n",
      "\n",
      "Total training time = 0.024352271223888996 hr!\n"
     ]
    }
   ],
   "source": [
    "batch_size=64; initial_epoch=0; final_epoch=5; DatagenShuffleSeed=0;\n",
    "\n",
    "Start=time.perf_counter()\n",
    "for ModelKey in ModelKeys:\n",
    "    ModelStart=time.perf_counter()\n",
    "    print('\\nTraining '+str(ModelKey)+'...')\n",
    "        \n",
    "    Model_Path = os.path.join(MasterPath,str(ModelKey))\n",
    "    \n",
    "    MdlChkpt_Path = os.path.join(Model_Path,\"MdlChkpt\",\"e{epoch:03d}_Acc{accuracy:.2f}_ValAcc{val_accuracy:.2f}.ckpt\")\n",
    "    MdlChkpt_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        MdlChkpt_Path, monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=True, \n",
    "        mode='auto', save_freq=\"epoch\"\n",
    "    )\n",
    "    TensorBoard_Path = os.path.join(Model_Path,\"logs\")\n",
    "    TensorBoard_cb = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir = TensorBoard_Path, histogram_freq=0, write_graph=False, write_images=False, update_freq=\"epoch\", \n",
    "        profile_batch=0, embeddings_freq=0, embeddings_metadata=None\n",
    "    )\n",
    "        \n",
    "    models[ModelKey].fit(\n",
    "        datagen.flow(x=X_Train, y=Y_Train, batch_size=batch_size,shuffle=True,sample_weight=None,seed=DatagenShuffleSeed,\n",
    "                     save_to_dir=None,save_prefix=\"\",save_format=\"png\",subset=None), \n",
    "        initial_epoch=initial_epoch, epochs=final_epoch, steps_per_epoch=len(X_Train)/batch_size, \n",
    "        verbose=1, callbacks=[MdlChkpt_cb, TensorBoard_cb], \n",
    "        validation_data=(X_Val,Y_Val), shuffle=True, use_multiprocessing=True\n",
    "    )\n",
    "       \n",
    "    print('\\n'+str(ModelKey)+' trained! Training time = '+ str((time.perf_counter()-ModelStart)/60) + ' min!')\n",
    "    print('Test Loss and Accuracy [Initial] [Final]')\n",
    "    for i,ModelKey in enumerate(ModelKeys):\n",
    "        eval=models[ModelKey].evaluate(X_Test,Y_Test, verbose=0)\n",
    "        print(InitialEval[i]+' '+str(eval))\n",
    "print('\\nTotal training time = '+ str((time.perf_counter()-Start)/(60*60)) + ' hr!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the latest version of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving mod_Xception_try\n",
      "WARNING:tensorflow:From C:\\Users\\biejds\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: \\\\fs9.nus.edu.sg\\bie\\MBELab\\jokhun\\Pro 1\\U2OS small mol screening\\mod_Xception_try\\LatestModel\\assets\n",
      "\n",
      "The latest version of each model has been saved!\n"
     ]
    }
   ],
   "source": [
    "for ModelKey in ModelKeys:\n",
    "    print('\\nSaving '+str(ModelKey))\n",
    "    Save_Path = os.path.join(MasterPath,str(ModelKey),\"LatestModel\")\n",
    "    models[ModelKey].save(\n",
    "        Save_Path, overwrite=False, include_optimizer=True, save_format=None,\n",
    "        signatures=None, options=None\n",
    "    )\n",
    "print('\\nThe latest version of each model has been saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
